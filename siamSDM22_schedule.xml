<meetings>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Meta Adversarial Weight for Unsupervised Domain Adaptation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:35:00</EventStartTime>
		<EventEndTime>2022-04-28T10:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Chang Liu</EventSpeakers>
		<EventSpeakerIDs>806752</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121823</EventHandoutURL>
		<EventDescription>Despite great progress in supervised image recognition,&#x0D;
a large performance drop is usually observed when deploying the model in the wild. Unsupervised domain adaptation (UDA) methods tackle the issue by aligning the source domain and the target domain. However, most existing adversarial based methods attempt to perform the alignment from a holistic view, ignoring the underlying class-level data structure in the target domain. As a result, the representations are distorted by adversarial alignment, leading to a negative transfer. Motivated by this issue, we first claim that this issue can be solved if there exists 'optimal' per-sample weights for adversarial alignment, and then devise a meta-learning framework to adaptively learn such adversarial weights. Specifically, we construct a meta-dataset with target-like distribution as meta knowledge, and use it to guide the learning of the optimal adversarial weights via a meta-learner. By this means, our framework can adaptively adjust the weights of all training samples in adversarial training based on the feedback from meta dataset and thus achieve the categorical-wise domain alignment. We conduct sufficient ablation studies and experiments to show the effectiveness of our approach. Our method is generic to existing domain alignment based methods and could achieve consistently improvements over three UDA classification benchmarks.&#x0D;
		</EventDescription>
		<EventParent>74599-SESS</EventParent>
		<EventUniqueID>121823</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<MeetingIAVMode></MeetingIAVMode>
		<PublishAutoRecordedVideo></PublishAutoRecordedVideo>
		<Capacity></Capacity>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Self-Supervision Based Semantic Alignment for Unsupervised Domain Adaptation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Ronghang Zhu</EventSpeakers>
		<EventSpeakerIDs>806812</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121867</EventHandoutURL>
		<EventDescription>Unsupervised domain adaptation aims to learn domain-invariant features across domains to transfer knowledge from a well-labeled source domain to an unlabeled target domain. Recently, some unsupervised domain adaptation methods focus on semantically aligning data distributions with pseudo-labels of the target domain. However, semantic alignment based on pseudo-labels has potential risks, e.g., inaccurate pseudo-labeling from classifier, and error accumulation from pseudo-label bias. To alleviate these risks, we propose a novel self-supervision based semantic alignment (S$^3$A) approach for unsupervised domain adaptation, which can jointly incorporate the source alignment and cross-domain target alignment forbetter semantic alignment across domains. S$^3$A consists of a two-stage semantic alignment procedure with self-supervision. One is to capture the discriminative structure of source domain by aligning source data to source class prototypes, and the other is to match each target data to its neighbor in source domain with self-supervision. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our proposed method, compared with the representative adversarial learning and self-supervised learning based unsupervised domain adaptation methods.</EventDescription>
		<EventParent>74599-SESS</EventParent>
		<EventUniqueID>121867</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Entropy Weight Allocation: Positive-Unlabeled Learning via Optimal Transport</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T11:35:00</EventStartTime>
		<EventEndTime>2022-04-28T11:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Wen Gu</EventSpeakers>
		<EventSpeakerIDs>806850</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121903</EventHandoutURL>
		<EventDescription>Positive-unlabeled learning (PU learning) aims to deal with the problem that only a fraction of positive instances are known. Due to the absence of negative instances, ordinary learning models cannot be directly applied. Existing PU learning methods either explicitly choose some unlabeled instances as negative instances in advance or reformulate the task as a weighted learning problem. Since working in such an ad-hoc fashion, these methods often suffer a bad performance and only have limited usage. This paper proposes a novel instance-dependent weighting method entropy weight allocation (EWA) for PU learning by optimal transport (OT). More specifically, we allocate each unlabeled instance an elaborate weight indicating the possibility that it is an underlying negative instance. Then any ordinary weighted learning models can be used to obtain a PU classifier. By concatenating EWA with four celebrated classification models, we show that EWA is a broad-spectrum weighting method that can boost almost all the mainstream machine learning models for PU learning.</EventDescription>
		<EventParent>74599-SESS</EventParent>
		<EventUniqueID>121903</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Positive Unlabeled Learning with a Sequential Selection Bias</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:55:00</EventStartTime>
		<EventEndTime>2022-04-28T11:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Walter Gerych</EventSpeakers>
		<EventSpeakerIDs>806902</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121926</EventHandoutURL>
		<EventDescription>In important domains from video stream analytics&#x0D;
to human context recognition, datasets are only partially-labeled. Worse yet, the labels are often applied&#x0D;
sequentially, as annotators choose labels frame-by-frame&#x0D;
or timestep-by-timestep in sequence. With labels not&#x0D;
collected independently, this results in sequential bias&#x0D;
in the labeling. Unfortunately, current state-of-the-art&#x0D;
methods for partially labeled data are rendered ineffective under sequential bias. In this work, we propose&#x0D;
a novel solution to tackling this open sequential bias&#x0D;
problem, called DeepSPU. DeepSPU recovers missing&#x0D;
labels by constructing a model of the sequentially biased labeling process itself. This labeling model is then&#x0D;
learned jointly with the prediction model that infers the&#x0D;
missing labels in an iterative training process. Further,&#x0D;
we regulate this training using a theoretically-justified&#x0D;
cost functions that prevent our model from converging&#x0D;
to incorrect but low-cost solution. Our experimental&#x0D;
studies demonstrate that DeepSPU consistently outperforms the state-of-the-art methods by over 10% on a rich&#x0D;
variety of real-world datasets.</EventDescription>
		<EventParent>74599-SESS</EventParent>
		<EventUniqueID>121926</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Continuously Generalized Ordinal Regression for Linear and Deep Models</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T11:15:00</EventStartTime>
		<EventEndTime>2022-04-28T11:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Fred Lu</EventSpeakers>
		<EventSpeakerIDs>806916</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121938</EventHandoutURL>
		<EventDescription>Input your abstract, including TeX commands, here.&#x0D;
&#x0D;
The abstract should be no longer than 1500 characters, including spaces.&#x0D;
Only input the abstract text. Don't include title&#x0D;
or author information here.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74599-SESS</EventParent>
		<EventUniqueID>121938</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Neighbor2Seq: Deep Learning on Massive Graphs by Transforming Neighbors to Sequences</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:35:00</EventStartTime>
		<EventEndTime>2022-04-28T10:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Meng Liu</EventSpeakers>
		<EventSpeakerIDs>806711</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121793</EventHandoutURL>
		<EventDescription>Modern graph neural networks (GNNs) use a message passing scheme and have achieved great success in many fields. However, this recursive design inherently leads to excessive computation and memory requirements, making it not applicable to massive real-world graphs. In this work, we propose the Neighbor2Seq to transform the hierarchical neighborhood of each node into a sequence. This novel transformation enables the subsequent mini-batch training for general deep learning operations, such as convolution and attention, that are designed for grid-like data and are shown to be powerful in various domains. Therefore, our Neighbor2Seq naturallyendows GNNs with the efficiency and advantages of deep learning operations on grid-like data by precomputing the Neighbor2Seq transformations. We evaluate our method on a massive graph, with more than $111$ million nodes and $1.6$ billion edges, as well as several medium-scale graphs. Results show that our proposed method is scalable to massive graphs and achieves superior performance across massive and medium-scale graphs. Our code is available at https://github.com/divelab/Neighbor2Seq.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74600-SESS</EventParent>
		<EventUniqueID>121793</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>DualCast: Friendship-Preference Co-Evolution Forecasting for Attributed Networks</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Hiroyoshi Ito</EventSpeakers>
		<EventSpeakerIDs>806712</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121794</EventHandoutURL>
		<EventDescription>If a person changes their interests and opinions, how will that change and affect their friendships? Conversely, when a person changes who they are friends with, how will that affect their interests and opinions. Clearly, the persons relationships and interests are related. For example, if several of a persons friends are smokers, but they themselves are not, they are likely to either start smoking as well or toreduce their relationships with the smokers and make new, non-smoking friends.  We propose DualCast, a method for predicting the evolution of friendship edges between nodes, as well as the attribute values (which represent opinions and preferences), of nodes in an attributed network. One of the main contributions of the present study is the ability to assume and estimate two scores for each node: the influence (its power to influence neighbors) and its susceptibility (how easily it can be influenced).&#x0D;
&#x0D;
Our DualCast has the following novel benefits: (A) Expressive: it can capture when links between nodes are dropped, as well as polarization that occurs with changes in interests, (B) Scalable: its performance is linear with input size, (C) Accurate: it is up to 8\% more accurate in forecasting links between nodes, and up to 20\% more accurate for attribute-values, when tested on publicly available, real datasets with 100K nodes.</EventDescription>
		<EventParent>74600-SESS</EventParent>
		<EventUniqueID>121794</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Leveraging Contextual Graphs for Stochastic Weight Completion in Sparse Road Networks</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:55:00</EventStartTime>
		<EventEndTime>2022-04-28T11:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Xiaolin Han</EventSpeakers>
		<EventSpeakerIDs>806741</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121807</EventHandoutURL>
		<EventDescription>Road network applications, such as navigation, incident detection, and Point-of-Interest (POI) recommendation, make extensive use of network edge weights (e.g., traveling times). Some of these weights can be missing, especially in a road network where traffic data may not be available for every road. In this paper, we study the stochastic weight completion (SWC) problem, which computes the weight distributions of missing road edges. This is difficult, due to the intricate temporal and spatial correlations among neighboring edges. Moreover, the road network can be sparse, i.e., there is a lack of traveling information in a large portion of the network. To tackle these challenges, we propose the Contextual Graph Completion (ConGC). We propose to incorporate the contextual properties about the road network (e.g., speed limits, number of lanes, road types) to provide finer granularity of spatial correlations. Moreover, ConGC incorporates temporal and periodic dimensions of the road traffic. We evaluate ConGC against existing methods on three real road network datasets. They show that ConGC is more effective and efficient than state-of-the-art solutions.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74600-SESS</EventParent>
		<EventUniqueID>121807</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Structure-Enhanced Heterogeneous Graph Contrastive Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T11:35:00</EventStartTime>
		<EventEndTime>2022-04-28T11:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yanqiao Zhu</EventSpeakers>
		<EventSpeakerIDs>806790</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121855</EventHandoutURL>
		<EventDescription>Recent years have seen a growing interest in Graph Contrastive Learning (GCL), which trains Graph Neural Networks (GNNs) without human annotations. Most prior GCL work focuses on homogeneous graphs and little attention has been paid to Heterogeneous Graphs (HGs) involving different types of nodes and edges. Moreover, earlier studies reveal that the explicit use of structure information of underlying graphs is useful for learning representations. Conventional GCL methods merely measure the likelihood of contrastive pairs according to node representations, which may not align with the true semantic similarities. How to leverage such structure information for GCL is not yet well-understood. To address the aforementioned challenges, this paper proposes a novel method dubbed STructure-EnhaNced heterogeneous graph ContrastIve Learning (STENCIL). At first, we generate multiple semantic views for HGs based on metapaths. Unlike most methods that maximize the consistency among these views, we propose a novel multiview contrastive aggregation objective to adaptively distill information from each view. In addition, we advocate the explicit use of structure embedding, which enriches the model with local structural patterns of the underlying HGs, so as to better mine true and hard negatives for GCL. Empirical studies on three real-world datasets show that our proposed method consistently outperforms existing state-of-the-art methods and even surpasses several supervised counterparts.&#x0D;
		</EventDescription>
		<EventParent>74600-SESS</EventParent>
		<EventUniqueID>121855</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Interpretable Molecular Graph Generation via Monotonic Constraints</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T11:15:00</EventStartTime>
		<EventEndTime>2022-04-28T11:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yuanqi Du</EventSpeakers>
		<EventSpeakerIDs>805782</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121865</EventHandoutURL>
		<EventDescription>Designing molecules with specific properties is a long-lasting research problem and is central to advancing crucial domains such as drug discovery and material science. Recent advances in deep graph generative models treat molecule design as graph generation problems which provide new opportunities toward the breakthrough of this long-lasting problem. Existing models, however, have many shortcomings, including poor interpretability and controllability toward desired molecular properties. This paper focuses on new methodologies for molecule generation with interpretable and controllable deep generative models, by proposing new monotonically-regularized graph variational autoencoders. The proposed models learn to represent the molecules with latent variables and then learn the correspondence between them and molecule properties parameterized by polynomial functions. To further improve the intepretability and controllability of molecule generation towards desired properties, we derive new objectives which further enforce monotonicity of the relation between some latent variables and target molecule properties such as toxicity and clogP. Extensive experimental evaluation demonstrates the superiority of the proposed framework on accuracy, novelty, disentanglement, and control towards desired molecular properties.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74600-SESS</EventParent>
		<EventUniqueID>121865</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>On Predicting and Generating a Good Break Shot in Billiards Sports</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP3</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:55:00</EventStartTime>
		<EventEndTime>2022-04-28T11:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Qianru Zhang</EventSpeakers>
		<EventSpeakerIDs>805865</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121126</EventHandoutURL>
		<EventDescription>\begin{abstract}&#x0D;
With the proliferation of tracking devices such as cameras and/or GPS sensors, sports data is being generated at an unprecedented speed and the interest in collecting some data from sports games has grown dramatically as well. The collected data facilitates various sports analytic tasks; however, these studies are mainly concerning with sports such as football and basketball. It remains largely unexplored for billiards sports though it is a popular sport of both strategy and physical skill, and this is mainly due to the lack of publicly available datasets. Motivated by this, we collect a dataset of billiards sports, which includes the layouts (i.e., locations) of billiards balls after performing break shots, called break shot layouts, the traces of the balls as a result of strikes (in the form of trajectories), and detailed statistics and performance indicators. On top of the dataset, we investigate several tasks, including prediction and generation on the layouts data and similarity search on the trajectory data, which can serve different users such as coaches, players and fans. We conduct extensive experiments on the collected dataset for the tasks, and the results demonstrate the superior performance of the methods proposed in this paper. &#x0D;
\end{abstract}&#x0D;
		</EventDescription>
		<EventParent>74596-SESS</EventParent>
		<EventUniqueID>121126</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Early Forecasting of the Impact of Traffic Accidents Using a Single Shot Observation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP3</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:35:00</EventStartTime>
		<EventEndTime>2022-04-28T10:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Zhiqian  Chen</EventSpeakers>
		<EventSpeakerIDs>800639</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121843</EventHandoutURL>
		<EventDescription>Predicting and measuring the impact of traffic collisions is crucial for Intelligent Transportation Systems (ITS). Numerous works in this field have successfully applied graph neural networks to ITS. Existing research on graph neural networks mainly relies on the graph Fourier transform, assuming neighborhood homophily.&#x0D;
The homophily assumption, on the other hand, makes it difficult to define abrupt signals such as traffic accidents. Our research proposes an abrupt graph wavelet network (AGWN) for forecasting the durations of traffic incidents using a single shot. To begin, graph wavelet (GW) is theoretically examined in terms of linear separability in comparison to graph Fourier (GF), demonstrating its advantage in modeling abrupt graph signals. Sensitivity analysis and admissibility conditions are utilized to further study the behavior of GW in abrupt graph signals, justifying the use of zero sum function as wavelet kernel. The synthetic data results support our proposed wavelet kernel's effectiveness in modeling a variety of abrupt signals, while real-world trials demonstrate that our method significantly outperforms baseline models in forecasting the duration of an accident impact.</EventDescription>
		<EventParent>74596-SESS</EventParent>
		<EventUniqueID>121843</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>ConLearn: Contextual-Knowledge-Aware Concept Prerequisite Relation Learning with Graph Neural Network</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP3</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T11:15:00</EventStartTime>
		<EventEndTime>2022-04-28T11:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Hao Sun</EventSpeakers>
		<EventSpeakerIDs>805487</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121859</EventHandoutURL>
		<EventDescription>Prerequisite relations among concepts are important for a wide range of educational applications, such as intelligent tutoring and curriculum planning. However, concept prerequisite relation learning is not trivial due to the sparsity of prerequisite relations. In this paper, we propose a contextual-knowledge-aware concept prerequisite relation learning approach called ConLearn. Four unique properties of the proposed approach are: (1) It transfers knowledge from large language model BERT to improve contextual representations of concepts; (2) It captures concept prerequisite transition patterns by applying graph neural network on concept prerequisite graph; (3) It is equipped with self-attention mechanism to fuse information from related concepts for target concept prerequisite relation classification; (4) No handcrafted features are used in our model, which makes our model easy to implement in downstream applications. Extensive experiments on three representative datasets demonstrate that our approach significantly outperforms the state-of-the-art methods.</EventDescription>
		<EventParent>74596-SESS</EventParent>
		<EventUniqueID>121859</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Modeling Reservoir Release in Stream Temperature Prediction Using Pseudo-Prospective Learning and Physical Simulations</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP3</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Xiaowei  Jia</EventSpeakers>
		<EventSpeakerIDs>800638</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121931</EventHandoutURL>
		<EventDescription>Input your abstract, including TeX commands, here.&#x0D;
&#x0D;
The abstract should be no longer than 1500 characters, including spaces.&#x0D;
Only input the abstract text. Don't include title&#x0D;
or author information here.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74596-SESS</EventParent>
		<EventUniqueID>121931</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Hypergraph Contrastive Learning for Electronic Health Records</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP3</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T11:35:00</EventStartTime>
		<EventEndTime>2022-04-28T11:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Derun Cai</EventSpeakers>
		<EventSpeakerIDs>807098</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121932</EventHandoutURL>
		<EventDescription>Input your abstract, including TeX commands, here.&#x0D;
&#x0D;
The abstract should be no longer than 1500 characters, including spaces.&#x0D;
Only input the abstract text. Don't include title&#x0D;
or author information here.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74596-SESS</EventParent>
		<EventUniqueID>121932</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>On the Persistence of Higher-Order Interactions in Real-World Hypergraphs</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP4</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:30:00</EventStartTime>
		<EventEndTime>2022-04-28T14:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Hyunjin Choo</EventSpeakers>
		<EventSpeakerIDs>805935</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121192</EventHandoutURL>
		<EventDescription>A hypergraph, which generalizes an ordinary graph, naturally represents group interactions as hyperedges (i.e., arbitrary-sized subsets of nodes). Such group interactions are ubiquitous: the sender and receivers of an email, the co-authors of a publication, and the items co-purchased by a customer, to name a few. A higher-order interaction (HOI) in a hypergraph is defined as the co-appearance of a set of nodes in any hyperedge. Our focus is the persistence of HOIs repeated over time, which is naturally interpreted as the strength of group relationships, aiming at answering three questions: (a) How do HOIs in real-world hypergraphs persist over time? (b) What are the key factors governing the persistence? (c) How accurately can we predict the persistence? &#x0D;
In order to answer these questions, we investigate the persistence of HOIs in 13 real-world hypergraphs. First, we define how to measure the persistence of HOIs. Then, we examine global patterns and anomalies in the persistence, revealing a power-law relationship. After that, we study the relations between the persistence and 16 structural features of HOIs, some of which are closely related to the persistence. Lastly, based on the 16 structural features, we assess the predictability of the persistence under various settings and find strong predictors. Note that predicting the persistence of HOIs has many potential applications, such as recommending items to be purchased together and predicting missing recipients of emails.</EventDescription>
		<EventParent>74601-SESS</EventParent>
		<EventUniqueID>121192</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>SAGA: Signal-Aware Graph Aggregation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP4</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T13:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Maxwell McNeil</EventSpeakers>
		<EventSpeakerIDs>806703</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121785</EventHandoutURL>
		<EventDescription>We propose a signal-aware graph aggregation framework called SAGA. The key idea is to group well-connected nodes whose behavior exhibits consistent temporal patterns. SAGA learns simultaneously  how to (i) aggregate the graph into supernode groups and (ii) represent the groups' collective temporal behavior succinctly via a sparse dictionary encoding. &#x0D;
The obtained aggregations offer insights into the functional organization of the graph and the learned model enables improved performance for state-of-the-art approaches for downstream tasks like temporal graph signal decomposition, forecasting and link prediction. We demonstrate, in both synthetic and real-world data sets, that SAGA's learned aggregations improve (i) reconstruction quality for temporal graph signals by up to $75\%$, (ii)link prediction accuracy by up to $40\%$ and (iii) the accuracy of forecasting by up to $63\%$ while also offering $50\%$ scalability improvements.</EventDescription>
		<EventParent>74601-SESS</EventParent>
		<EventUniqueID>121785</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Neural Graph Matching for Pre-Training Graph Neural Networks</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP4</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:50:00</EventStartTime>
		<EventEndTime>2022-04-28T15:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yupeng Hou</EventSpeakers>
		<EventSpeakerIDs>806713</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121795</EventHandoutURL>
		<EventDescription>Recently, graph neural networks (GNNs) have been shown powerful capacity at modeling structural data. However, when adapted to downstream tasks, it usually requires abundant task-specific labeled data, which can be extremely scarce in practice. A promising solution to data scarcity is to pre-train a transferable and expressive GNN model on large amounts of unlabeled graphs or coarse-grained labeled graphs. Then the pre-trained GNN is fine-tuned on downstream datasets with task-specific fine-grained labels.&#x0D;
&#x0D;
In this paper, we present a novel Graph Matching based GNN Pre-Training framework, called GMPT. Focusing on a pair of graphs, we propose to learn structural correspondences between them via neural graph matching, consisting of both intra-graph message passing and inter-graph message passing. In this way, we can learn adaptive representations for a given graph when paired with different graphs, and both node- and graph-level characteristics are naturally considered in a single pre-training task. The proposed method can be applied to fully self-supervised pre-training and coarse-grained supervised pre-training. We further propose an approximate contrastive training strategy to significantly reduce time/memory consumption. Extensive experiments on multi-domain, out-of-distribution benchmarks have demonstrated the effectiveness of our approach. The code is available at: https://github.com/RUCAIBox/GMPT.</EventDescription>
		<EventParent>74601-SESS</EventParent>
		<EventUniqueID>121795</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Transition Matrix Representation of Trees with Transposed Convolutions</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP4</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:10:00</EventStartTime>
		<EventEndTime>2022-04-28T14:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Jaemin Yoo</EventSpeakers>
		<EventSpeakerIDs>801426</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121868</EventHandoutURL>
		<EventDescription>How can we effectively find the best structures in tree models? Tree models have been favored over complex black box models in domains where interpretability is crucial for making irreversible decisions. However, searching for a tree structure that gives the best balance between the performance and theinterpretability remains a challenging task. In this paper, we propose TART (Transition Matrix Representation with Transposed Convolutions), our novel generalized tree representation for optimal structural search. TART represents a tree model with a series of transposed convolutions that boost the speed of inference by avoiding the creation of transition matrices. As a result, TART allows one to search for the best tree structure with a few design parameters, achieving higher classification accuracy than those of baseline models in feature-based datasets.</EventDescription>
		<EventParent>74601-SESS</EventParent>
		<EventUniqueID>121868</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Diverse and Experienced Group Discovery via Hypergraph Clustering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP4</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:50:00</EventStartTime>
		<EventEndTime>2022-04-28T14:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Ilya Amburg</EventSpeakers>
		<EventSpeakerIDs>789375</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121906</EventHandoutURL>
		<EventDescription>In forming teams or groups, one often aims to balance expertise in a main focus area while also encouraging diversity of skills in each team. In this paper we model the problem of finding diverse groups of individuals who have expertise in a given task as a clustering problem on hypergraphs with heterogeneous edge types that encode past experience types of groups. Unlike complementary problems that seek to find fair or balanced clusters (e.g., in terms of some protected node attributes), our model encourages diversity of past \textit{experience} within these groups by striking a balance between experience and diversity with respect to node participation in edge types. While optimizing our diversity-regularized objective is NP-hard, we design a 2-approximation algorithm that works for a more general class of problems where each node is allowed to have a preference for clusters, and illustrate a technique for computing regularization strength bounds that reveal meaningful diversity/experience tradeoff regimes. We illustrate the utility of our framework on several real-life datasets -- most notably on online review platform data -- to curate sets of reviews for a given type of product which exhibit a tradeoff between reviewer experience, or familiarity with a product type, and diversity, or the reviewer's tendency to review other product types. In the setting allowing for node preferences, we show that our framework discovers sets of reviews sensitive to user preference.</EventDescription>
		<EventParent>74601-SESS</EventParent>
		<EventUniqueID>121906</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Towards Similarity-Aware Time-Series Classification</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP5</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:10:00</EventStartTime>
		<EventEndTime>2022-04-28T14:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Daochen Zha</EventSpeakers>
		<EventSpeakerIDs>806042</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121275</EventHandoutURL>
		<EventDescription>We study time-series classification (TSC), a fundamental task of time-series data mining. Prior work has approached TSC from two major directions: (1) similarity-based methods that classify time-series based on the nearest neighbors, and (2) deep learning models that directly learn the representations for classification in a data-driven manner. Motivated by the different working mechanisms within these two research lines, we aim to connect them in such a way as to jointly model time-series similarities and learn the representations. This is a challenging task because it is unclear how we should efficiently leverage similarity information. To tackle the challenge, we propose \textbf{Sim}ilarity-Aware \textbf{T}ime-\textbf{S}eries \textbf{C}lassification (SimTSC), a conceptually simple and general framework that models similarity information with graph neural networks (GNNs). Specifically, we formulate TSC as a node classification problem in graphs, where the nodes correspond to time-series, and the links correspond to pair-wise similarities. We instantiate SimTSC with ResNet as the backbone and Dynamic Time Warping (DTW) as the similarity measure. Extensive experiments on the full UCR datasets and several multivariate datasets demonstrate the effectiveness of incorporating similarity information into deep learning models in both supervised and semi-supervised settings. Our code is &#x0D;
available at \url{https://github.com/daochenzha/SimTSC}.</EventDescription>
		<EventParent>74602-SESS</EventParent>
		<EventUniqueID>121275</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Ib-Gan: A Unified Approach for Multivariate Time Series Classification under Class Imbalance</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP5</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:50:00</EventStartTime>
		<EventEndTime>2022-04-28T15:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Grace Deng</EventSpeakers>
		<EventSpeakerIDs>806728</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121806</EventHandoutURL>
		<EventDescription>Classification of large multivariate time series with strong class imbalance is an important task in real-world applications. Standard methods of class weights, oversampling, or parametric data augmentation do not always yield significant improvements for predicting minority classes of interest. Non-parametric data augmentation with Generative Adversarial Networks (GANs) offers a promising solution. We propose Imputation Balanced GAN (IB-GAN), a novel method that joins data augmentation and classification in a one-step process via an imputation-balancing approach. IB-GAN uses imputation and resampling techniques to generate higher quality samples from randomly masked vectors than from white noise, and augments classification through a class-balanced set of real and synthetic samples. Imputation hyperparameter $p_{miss}$ allows for regularization of classifier variability by tuning innovations introduced via generator imputation. IB-GAN is simple to train and model-agnostic, pairing any deep learning classifier with a generator-discriminator duo and resulting in higher accuracy for under-observed classes. Empirical experiments on open-source UCR data and a 90K product dataset show significant performance gains against state-of-the-art parametric and GAN baselines.</EventDescription>
		<EventParent>74602-SESS</EventParent>
		<EventUniqueID>121806</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Learning Time-Series Shapelets Enhancing Discriminability</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP5</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:50:00</EventStartTime>
		<EventEndTime>2022-04-28T14:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Akihiro Yamaguchi</EventSpeakers>
		<EventSpeakerIDs>793446</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121857</EventHandoutURL>
		<EventDescription>Shapelets are subsequences that are effective for classifying time-series instances. Joint learning of both classifiers and shapelets has recently been studied because this approach improves algorithmic complexity and classification performance. However, the existing methods lack the power of feature discrimination due to using traditional sigmoid cross-entropy loss functions. To enhance feature discriminability, we propose self-adaptive scaling of the loss functions, inspired by the recent discriminative loss in computer vision. In addition, we propose a theoretically sound regularization that enhances feature discriminability and maintains shapelet interpretability by shrinking appropriate features. Using UCR datasets, we demonstrate improved area under the curve and interpretability of shapelets with a small number of shapelets.</EventDescription>
		<EventParent>74602-SESS</EventParent>
		<EventUniqueID>121857</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Joint Time Series Chain: Detecting Unusual Evolving Trend Across Time Series</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP5</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:30:00</EventStartTime>
		<EventEndTime>2022-04-28T14:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Li Zhang</EventSpeakers>
		<EventSpeakerIDs>794663</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121870</EventHandoutURL>
		<EventDescription>Time series chain (TSC) is a recently introduced concept that captures the evolving patterns in large scale time series. Informally, a time series chain is a temporally ordered set of subsequences, in which consecutive subsequences in the chain are similar to one another, but the last and the first subsequences maybe be dissimilar. Time series chain has the great potential to reveal a latent unusual evolving trend in the time series, or identify precursors of important events in a complex system. Unfortunately, existing definitions of time series chains only consider finding chains in a single time series. As a result, they are likely to miss unexpected evolving patterns in interrupted time series, or across two related time series. To address this limitation, in this work, we introduce a new definition called Joint Time Series Chain, which is specially designed for the task of finding unexpected evolving trend across interrupted time series or two related time series. Our definition focuses on mitigating the robustness issues caused by the gap or interruption in the time series. We further propose an effective ranking criterion to identify the best chain. We demonstrate that our proposed approach outperforms existing TSC work in locating unusual evolving patterns through extensive empirical evaluations. We further demonstrate the utility of our work with a real-life manufacturing application from Intel. &#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74602-SESS</EventParent>
		<EventUniqueID>121870</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Error-Bounded Approximate Time Series Joins Using Compact Dictionary Representations of Time Series</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP5</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T13:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Chin-Chia Michael Yeh</EventSpeakers>
		<EventSpeakerIDs>806866</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121907</EventHandoutURL>
		<EventDescription>The matrix profile is an effective data mining tool that provides similarity join functionality for time series data. Since the introduction of the matrix profile five years ago, multiple efforts have been made to speed up the computation with approximate joins; however, the majority of these efforts only focus on self-joins. In this work, we show that it is possible to efficiently perform approximate inter-time series similarity joins with error bounded guarantees by creating a compact ``dictionary" representation of time series. Using the dictionary representation instead of the original time series, we are able to improve the throughput of an anomaly mining system by at least 20X, with essentially no decrease in accuracy. As a side effect, the dictionaries also summarize the time series in a semantically meaningful way and can provide intuitive and  actionable insights.</EventDescription>
		<EventParent>74602-SESS</EventParent>
		<EventUniqueID>121907</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Sssnet: Semi-Supervised Signed Network Clustering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP6</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:10:00</EventStartTime>
		<EventEndTime>2022-04-28T14:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yixuan He</EventSpeakers>
		<EventSpeakerIDs>805481</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121127</EventHandoutURL>
		<EventDescription>Node embeddings are a powerful tool in network analysis; yet, their full potential for the important node clustering task has not been fully exploited. In particular, most SOTA methods  generating node embeddings of signed networks focus on link sign prediction, and those that pertain to node clustering are usually not GNN methods. Here, we introduce a novel probabilistic balanced normalized cut loss for training nodes in a GNN framework for semi-supervised signed clustering, called SSSNET. The method is end-to-end in combining embedding generation and clustering without an intermediate step; it has node clustering as main focus, with an emphasis on polarization effects arising in networks. The main novelty of our approach is a new take on the role of social balance theory for signed network embeddings. The standard heuristic for justifying the criteria for the embeddings hinges on the assumption that "an enemy's enemy is a friend". Here, instead, a neutral stance is assumed on whether or not the enemy of an enemy is a friend. Experimental results on various data sets, including  a synthetic signed stochastic block model, a polarized version of it, and real-world data at different scales, demonstrate that SSSNET can achieve comparable or better results than SOTA spectral clustering methods, for a wide range of noise and sparsity levels. SSSNET complements existing methods through the possibility of including exogenous information, in the form of node-level features or labels.</EventDescription>
		<EventParent>74603-SESS</EventParent>
		<EventUniqueID>121127</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Automatic Parameter Selection for Non-Redundant Clustering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP6</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T13:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Collin Leiber</EventSpeakers>
		<EventSpeakerIDs>805891</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121146</EventHandoutURL>
		<EventDescription>High-dimensional datasets often contain multiple meaningful clusterings in different subspaces. For example, objects can be clustered either by color, weight, or size, revealing different interpretations of the given dataset.&#x0D;
A variety of approaches are able to identify such non-redundant clusterings. However, most of these methods require the user to specify the expected number of subspaces and clusters for each subspace. Stating these values is a non-trivial problem and usually requires detailed knowledge of the input dataset. In this paper, we propose a framework that utilizes the Minimum Description Length Principle (MDL) to detect the number of subspaces and clusters per subspace automatically. We describe an efficient procedure that greedily searches the parameter space by splitting and merging subspaces and clusters within subspaces. Additionally, an encoding strategy is introduced that allows us to detect outliers in each subspace. Extensive experiments show that our approach is highly competitive to state-of-the-art methods.</EventDescription>
		<EventParent>74603-SESS</EventParent>
		<EventUniqueID>121146</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Unseen Anomaly Detection on Networks via Multi-Hpersphere Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP6</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:50:00</EventStartTime>
		<EventEndTime>2022-04-28T15:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Shuang Zhou</EventSpeakers>
		<EventSpeakerIDs>805915</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121163</EventHandoutURL>
		<EventDescription>Network anomaly detection is a crucial task since a few anomalies can cause huge losses. Semi-supervised anomaly detection methods can effectively leverage a small number of labels as prior knowledge to enhance detection accuracy. But in real-world scenarios, novel types of anomalies (i.e., unseen anomalies) usually exist on networks which may present different characteristics with the seen anomalies and are hard to be identified by prior semi-supervised anomaly detection methods. In this paper, we propose the novel problem of unseen network anomaly detection that aims to identify both seen and unseen anomalies to eliminate potential dangers. Accordingly, we propose a method called Multi-hypersphere Graph Learning (MHGL) to effectively leverage existing labels by learning fine-grained normal patterns to discriminate anomalies. Experiments demonstrate that MHGL outperforms state-of-the-art methods significantly.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74603-SESS</EventParent>
		<EventUniqueID>121163</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Constrained Mean Shift Clustering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP6</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:50:00</EventStartTime>
		<EventEndTime>2022-04-28T14:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Maximilian Schier</EventSpeakers>
		<EventSpeakerIDs>806382</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121538</EventHandoutURL>
		<EventDescription>In this paper, we present Constrained Mean Shift (CMS), a novel approach for mean shift clustering under sparse supervision using cannot-link constraints. The constraints provide a guidance in constrained clustering indicating that the respective pair should not be assigned to the same cluster. Our method introduces a density-based integration of the constraints to generate individual distributions of the sampling points per cluster. We also alleviate the (in general very sensitive) mean shift bandwidth parameter by proposing an adaptive bandwidth adjustment which is especially useful for clustering imbalanced data sets. Several experiments show that our approach achieves better performance compared to state-of-the-art methods both clustering synthetic data sets as well as clustering encoded features of real-world image data sets.</EventDescription>
		<EventParent>74603-SESS</EventParent>
		<EventUniqueID>121538</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Multi-Class Label Noise Learning via Loss Decomposition and Centroid Estimation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP6</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T14:30:00</EventStartTime>
		<EventEndTime>2022-04-28T14:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yongliang Ding</EventSpeakers>
		<EventSpeakerIDs>806853</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121904</EventHandoutURL>
		<EventDescription>In real-world scenarios, many large-scale datasets often contain inaccurate labels, which may confuse model training and lead to performance degradation. To overcome this issue, Label Noise Learning (LNL) has recently attracted much attention, and various methods have been proposed to design an unbiased risk estimator to the noise-free dataset to combat such label noise. Among them, a trend of works based on Loss Decomposition and Centroid Estimation (LDCE) has shown very promising performance. However, existing LNL methods based on LDCE are only designed for binary classification, and they are not directly extendable to multi-class situations. In this paper, we propose a novel multi-class robust learning method for LDCE, which is termed ``MC-LDCE'. Specifically, we decompose the commonly adopted loss function into a label-dependent part and a label-independent part, in which only the former is influenced by label noise. Further, by defining a new form of data centroid, we transform the recovery problem of a label-dependent part to a centroid estimation problem. Finally, by critically examining the mathematical expectation of clean data centroid given the observed noisy set, the centroid can be estimated which helps to build an unbiased risk estimator for multi-class learning. The experimental results on five public datasets demonstrate the superiority of the proposed MC-LDCE against other representative LNL methods in tackling multi-class label noise problem.</EventDescription>
		<EventParent>74603-SESS</EventParent>
		<EventUniqueID>121904</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Ganblr++: Incorporating Capacity to Generate Numeric Attributes and Leveraging Unrestricted Bayesian Networks</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T17:00:00</EventStartTime>
		<EventEndTime>2022-04-28T17:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yishuo Zhang</EventSpeakers>
		<EventSpeakerIDs>806718</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121796</EventHandoutURL>
		<EventDescription>Generative Adversarial Networks (\texttt{GANS}) models have led to a major breakthrough in data generation of various sorts. Over the years, we have seen several applications of \texttt{GANS}-based learning for tabular data generation as well. Very recently, \texttt{GANS}-based learning by incorporating Bayesian Networks (\texttt{BN}) as generator and discriminator -- \texttt{GANBLR}, has shown to lead to state-of-the-art (\texttt{SOTA}) results for tabular data generation. Despite the impressive performance, \texttt{GANBLR} has an inherent weakness that it can only generate data with categorical attributes. Additionally, the model is trained and tested only with a restricted Bayesian Network. &#x0D;
In this work, we have proposed an extension over~\texttt{GANBLR} framework -- \texttt{GANBLR++}, that has the capacity to generate numeric attributes, by leveraging~\texttt{Dirichlet Mixture Model}.&#x0D;
We also leverage unrestricted \texttt{BN} in \texttt{GANBLR} framework, and discuss how the use of unrestricted \texttt{BN} can lead to better quality data, as well as more interpretable model.&#x0D;
We evaluate the effectiveness of \texttt{GANBLR++} on wide range of datasets by demonstrating that it generates data of better quality as compared to existing \texttt{SOTA} models for tabular (numeric and categorical) data generation such as~\texttt{CTGAN},~\texttt{MedGAN} and~\texttt{TableGAN}.&#x0D;
		</EventDescription>
		<EventParent>74607-SESS</EventParent>
		<EventUniqueID>121796</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Flexible Image Captioning via Internal Understanding and External Reasoning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T17:20:00</EventStartTime>
		<EventEndTime>2022-04-28T17:35:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Jiahui Wei</EventSpeakers>
		<EventSpeakerIDs>806723</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121798</EventHandoutURL>
		<EventDescription>Image captioning aims to generate a grammatically correct and semantically accurate natural language description of a given image. In order to capture the more complex information contained in the image and expand the relevant external knowledge outside the image to generate better image caption, this paper proposes an end-to-end image captioning framework Flexible Image Captioning via Internal Understanding and External Reasoning (IUER) based on the Transformer model. IUER enhances visual understanding ability and caption reasoning ability to improve image captioning performance. To achieve this goal, we use the semantic features of the core objects detected from the image to guide the visual feature, where the visual feature incorporate the spatial positional relationship information between the objects, then we introduce external knowledge network to obtain information other than the intuitive content from the image. In this way, a high-quality image caption sentence about the given image is generated. Experiments prove that our method is superior to the baseline model and comparable to other state-of-the-art methods.&#x0D;
		</EventDescription>
		<EventParent>74607-SESS</EventParent>
		<EventUniqueID>121798</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Hybrid Tokenization and Datasets for Solving Mathematics and Science Problems Using Transformers</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:40:00</EventStartTime>
		<EventEndTime>2022-04-28T16:55:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Pawan Kumar</EventSpeakers>
		<EventSpeakerIDs>806764</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121841</EventHandoutURL>
		<EventDescription>Transformers, which were introduced for solving the task of machine translation, have expanded their utility in multiple domains. A recent application of transformers is in solving elementary mathematics problems. In this paper, we use a hybrid tokenization technique for encoding the mathematics and science problems and answers, which is used to train the transformer. We compare the performance of our tokenization with that of the char-to-char tokenzation in solving various types of mathematics and science problems. We discuss the accuracy, memory usage, and time to train the model with proposed tokenization. The proposed tokenization shows higher accuracy for some problems, and requires lesser memory compared to char-to-char tokenization. We propose an extended dataset of science andmathematics problems that consists of billions of samples in question-answer format in raw text.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74607-SESS</EventParent>
		<EventUniqueID>121841</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Noisy Truncated SGD: Optimization and Generalization</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T17:40:00</EventStartTime>
		<EventEndTime>2022-04-28T17:55:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yingxue Zhou</EventSpeakers>
		<EventSpeakerIDs>794533</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121845</EventHandoutURL>
		<EventDescription>Recent empirical work on stochastic gradient descent (SGD) applied to over-parameterized deep learning has shown that most gradient components over epochs are quite small.  Inspired by such observations, we rigorously study properties of Truncated SGD (T-SGD), that truncates the majority of small gradient components to zeros. Considering non-convex optimization problems, we show that the convergence rate of T-SGD matches the order of vanilla SGD. We also establish the generalization error bound for T-SGD. Further, we propose Noisy Truncated SGD (NT-SGD), which adds Gaussian noise to the truncated gradients. We prove that NT-SGD has the same convergence rate as T-SGD for non-convex optimization problems. We demonstrate that with the help of noise, NT-SGD can provably escape from saddle points and requires less noise compared to previous related work. We also prove that NT-SGD achieves better generalization error bound compared to T-SGD because of the noise. Our generalization analysis is based on uniform stability and we show that additional noise in the gradient update can boost the stability. Our experiments on {a variety of benchmark} datasets with various network architectures verify that NT-SGD matches the speed and accuracy of vanilla SGD while effectively working with sparse gradients, and can successfully escape poor local minima.</EventDescription>
		<EventParent>74607-SESS</EventParent>
		<EventUniqueID>121845</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Capturing Model Uncertainty with Data Augmentation in Deep Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:00:00</EventStartTime>
		<EventEndTime>2022-04-28T16:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Ying Zhao</EventSpeakers>
		<EventSpeakerIDs>780836</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121915</EventHandoutURL>
		<EventDescription>Neural network models have been widely used in many fields and achieved many successes. Quantifying model uncertainty, which is able to show the reliability degree of predictions, has attracted more and more researchers' attention. Bayesian neural networks are well known in this category, as they could provide the distributions of predictions, but it takes a prohibitive computational cost to train them. In this paper, we develop a novel way to quantify the model uncertainty of the models trained with data augmentation, i.e., performing data transformation such as adding Gaussian noise to input data before every forward pass of model training and inference. We show that data augmentation is equivalent to performing a corresponding transformation on model weights for some data augmentation methods. We also show that training with Gaussian noise approximates Bayesian inference in Gaussian processes. The experiments on both regression and classification tasks demonstrate that the proposed data augmentation models achieve better predictive performance than baseline models. For all four datasets, the calculated predictive uncertainty can be used as an uncertainty  function in selective prediction to reject high risk predictions effectively.&#x0D;
		</EventDescription>
		<EventParent>74607-SESS</EventParent>
		<EventUniqueID>121915</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Input Selection for Bandwidth-Limited Neural Network Inference</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:20:00</EventStartTime>
		<EventEndTime>2022-04-28T16:35:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Stefan Oehmcke</EventSpeakers>
		<EventSpeakerIDs>806893</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121917</EventHandoutURL>
		<EventDescription>Data are often accommodated on centralized storage servers. This is the case, for instance, in remote sensing and astronomy, where projects produce several petabytes of data every year. While machine learning models are often trained on relatively small subsets of the data, the inference phase typically requires  transferring significant amounts of data between the servers and the clients. In many cases, the bandwidth available per user is limited, which then renders the data transfer to be one of the major bottlenecks. In this work, we propose a framework that automatically selects the relevant parts of the input data for a given neural network. The model as well as the associated selection masks are trained simultaneously such that a good model performance is achieved while only a minimal amount of data is selected. During the inference phase, only those parts of the data have to be transferred between the server and the client. We propose both instance-independent and instance-dependent selection masks. The former ones are the same for all instances to be transferred, whereas the latter ones allow for variable transfer sizes per instance. Our experiments show that it is often possible to significantly reduce the amount of data needed to be transferred without affecting the model quality much.</EventDescription>
		<EventParent>74607-SESS</EventParent>
		<EventUniqueID>121917</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Multiperiod Corporate Default Prediction Through Neural Parametric Family Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP8</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:00:00</EventStartTime>
		<EventEndTime>2022-04-28T16:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Wei-Lun Luo</EventSpeakers>
		<EventSpeakerIDs>805781</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121143</EventHandoutURL>
		<EventDescription>Default analysis plays an essential role in financial markets because it narrows the information gap between borrowers and lenders. Of late, machine learning-based methods have found their way to default analysis and typically view it as a risk classification task by slotting obligors into risk categories. The quality of such an approach is assessed by its prediction accuracy in risk rankings. Rarely considered but important are issues on the predicted numbers of default occurrences and the term structure of cumulative default probabilities for which classification tools are by nature silent. In this paper, we depart from the typical practice of risk classification and focus on employing machine learning to estimate the term structure of cumulative default probabilitiesa structured estimation that contains default probabilities from short-term to long-term periods. To this end, we formulate the task as a problem of parametric family learning via a neural model consisting of two segments: parameter generation and parametric family determination. The proposed neural approach offers added flexibility in improving long-term default predictions. Moreover, the carefully designed model successfully maintains vital economic characteristics of its predictions. Experiments on a US corporate default dataset show that our approach achieves measurably better prediction performance in both risk classification and matching the predicted numbers of default occurrences with the actual ones.</EventDescription>
		<EventParent>74608-SESS</EventParent>
		<EventUniqueID>121143</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Brnet: Branched Residual Network for Fast and Accurate Predictive Modeling of Materials Properties</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP8</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T17:00:00</EventStartTime>
		<EventEndTime>2022-04-28T17:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Vishu Gupta</EventSpeakers>
		<EventSpeakerIDs>806075</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121305</EventHandoutURL>
		<EventDescription>Machine Learning (ML) and Deep Learning (DL) have become increasingly popular in the field of materials science for building property prediction models owing to their ability to efficiently extract and understand data-driven relationships between materials composition, structure, and properties. While fully connected layers have been widely used in deep neural networks to predict materials properties, simply adding more and more layers to create a deep model often degrades their performance due to the vanishing gradient problem, thereby limiting usage. In this paper, we study and propose architectural principles for building deep regression neural networks comprising fully connected layers with numerical vectors that bypass manual feature engineering. We introduce a novel deep regression neural network with branched residual learning, BRNet, consisting of branching of layers to maximize variation of features learned from the input or previous layer and places skip connections after each layer to minimize the information loss due to vanishing gradient. We perform BRNet model training for inorganic material properties using numerical vectors representing the elemental fractions of the compositions of the respective materials and compare its performance against other traditional ML and DL techniques. Using multiple datasets for training and testing, we show that BRNet models are significantly more accurate than the state-of-the-art ML methods and DL models for all data sizes. </EventDescription>
		<EventParent>74608-SESS</EventParent>
		<EventUniqueID>121305</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Efficient Wind Speed Nowcasting with GPU-Accelerated Nearest Neighbors Algorithm</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP8</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:20:00</EventStartTime>
		<EventEndTime>2022-04-28T16:35:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Arnaud Pannatier</EventSpeakers>
		<EventSpeakerIDs>806779</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121847</EventHandoutURL>
		<EventDescription>  This paper proposes a simple yet efficient high-altitude wind nowcasting pipeline.&#x0D;
  It processes efficiently a vast amount of live data recorded by airplanes over the whole airspace and reconstructs the wind field with good accuracy.&#x0D;
  It creates a unique context for each point in the dataset and then extrapolates from it. As creating such context is computationally intensive,&#x0D;
  this paper proposes a novel algorithm that reduces the time and memory cost by efficiently fetching nearest neighbors in a data set whose elements are organized along smooth trajectories that can be approximated with piece-wise linear structures.&#x0D;
  We introduce an efficient and exact strategy implemented through algebraic tensorial operations, which is well-suited to modern GPU-based computing infrastructure.&#x0D;
  This method employs a scalable Euclidean metric and allows masking data points along one dimension.&#x0D;
  When applied, this method is more efficient than plain Euclidean $k$-NN and other well-known data selection methods such as KDTrees and provides a several-fold speedup.&#x0D;
  We provide a PyTorch implementation and a novel data set to replicate empirical results.</EventDescription>
		<EventParent>74608-SESS</EventParent>
		<EventUniqueID>121847</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Textbook Enhanced Student Learning Outcome Prediction</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP8</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T17:20:00</EventStartTime>
		<EventEndTime>2022-04-28T17:35:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tianqi Wang</EventSpeakers>
		<EventSpeakerIDs>801501</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121858</EventHandoutURL>
		<EventDescription>To enable personalized learning, it is critical and essential to automatically estimate the mastery levels of students, which motivates the student learning outcome prediction task. Although several models have been proposed, most of them ignore the relations between questions and knowledge concepts. However, manually labeling the relations among questions only by experts is impractical. Thus, an automatic inference of such relations is needed. In addition, different students may use different concepts when answering the same question, which makes the inferred relation between a question and concepts differ among students. &#x0D;
 To address these challenges, we propose to leverage information from a textbook to link questions with knowledge concepts that a student may retrieve. Correspondingly, we propose a novel framework named TESLOP, which can effectively utilize both textual and structural information in the textbook for student learning outcome prediction. &#x0D;
 The model simulates the process of a student picking an answer by recalling the knowledge obtained from the textbook and utilizing the knowledge to pick a correct answer. &#x0D;
Experimental results show that the proposed TESLOP framework outperforms state-of-the-art baselines, which confirms the importance of leveraging textbook information in the student learning outcome prediction task. It also demonstrates that the proposed  way of integrating such information is effective. </EventDescription>
		<EventParent>74608-SESS</EventParent>
		<EventUniqueID>121858</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Hierarchical Knowledge Transfer Networks for Traffic Accident Forecasting on Heterogeneous Spatio-Temporal Data</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP8</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:40:00</EventStartTime>
		<EventEndTime>2022-04-28T16:55:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Bang An</EventSpeakers>
		<EventSpeakerIDs>806883</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121913</EventHandoutURL>
		<EventDescription>Traffic accident forecasting is a significant problem for transportation management and public safety. However, this problem is challenging due to the spatial heterogeneity of the environment and the sparsity of accidents in space and time. The occurrence of traffic accidents is affected by complex dependencies among spatial and temporal features. Recent traffic accident prediction methods have attempted to use deep learning models to improve accuracy. However, most of &#x0D;
these methods either focus on small-scale and homogeneous areas such as populous cities or simply use sliding-window-based ensemble methods, which are inadequate to handle heterogeneity in large regions. To address these limitations, this paper proposes a novel Hierarchical Knowledge Transfer Network (HintNet) model to better capture irregular heterogeneity patterns. HintNet performs a multi-level spatial partitioning to separate sub-regions with different risks and learns a deep network model for each level using spatio-temporal and graph convolutions. Through knowledge transfer across levels, HintNet archives both higher accuracy and higher training efficiency. Extensive experiments on a real-world accident dataset from the state of Iowa demonstrate that HintNet outperforms the state-of-the-art methods on spatially heterogeneous and large-scale areas.</EventDescription>
		<EventParent>74608-SESS</EventParent>
		<EventUniqueID>121913</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Hg-Meta: Graph Meta-Learning over Heterogeneous Graphs</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP9</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T11:35:00</EventStartTime>
		<EventEndTime>2022-04-29T11:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Qiannan Zhang</EventSpeakers>
		<EventSpeakerIDs>806755</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121830</EventHandoutURL>
		<EventDescription>Prevailing supervised graph neural networks suffer from potential performance degradation in the label sparsity case. Though increasing attention has been paid to graph few-shot learning methods for learning effective graph embeddings under the scarcity of labeled data, most existing works study homogeneous graphs while ignoring the ubiquitousness of heterogeneous graphs (HG), where multi-typed nodes are interconnected by multi-typed edges. To this end, we propose to tackle few-shot learning on HG and develop a novel model for Heterogeneous Graph Meta-learning (a.k.a. HG-Meta). Regarding the graph heterogeneity, HG-Meta firstly builds a graph encoder to aggregate heterogeneous neighbors information from multiple semantic contexts (generated by meta-paths). Secondly, to train the graph encoder with meta-learning in a few-shot scenario, HG-Meta tackles meta-task differences produced from meta-task sampling procedure on HG with a task feature scaling module and a degree based task attention module. To further alleviate low-data problem, HG-Meta leverages unlabelled information in HG with auxiliary self-supervised learning task alongside the meta-optimization process to facilitate node embedding. Extensive experiments on two HG datasets demonstrate that HG-Meta outperforms state-of-the-art methods for multiple few-shot node classification tasks.</EventDescription>
		<EventParent>74611-SESS</EventParent>
		<EventUniqueID>121830</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Dense and Well-Connected Subgraph Detection in Dual Networks</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP9</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tianyi  Chen</EventSpeakers>
		<EventSpeakerIDs>800629</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121844</EventHandoutURL>
		<EventDescription>Dense subgraph discovery is a fundamental problem in graph mining whose goal is to extract a dense subgraph from a given graph, and it has a wide range of applications. However, numerous real-world applications, ranging from computational biology, and computational neuroscience to computational social science, take as input a dual graph, namely a pair of graphs on the same set of nodes. Despite the large number of such applications, research on dense subgraph discovery (DSD) has focused on a single graph input, with few notable exceptions. In this work, we contribute to this line of research by studying the following novel algorithmic problem:&#x0D;
&#x0D;
Given a pair of graphs $G,H$ on the same set of nodes $V$, how do we find a subset of nodes $S \subseteq&#x0D;
V$ that induces a well-connected subgraph in $G$, and a dense subgraph in $H$?&#x0D;
&#x0D;
Our formulation generalizes previous research, by enabling to control the connectivity constraint on $G$. We propose a mathematical formulation, and we prove that it is solvable exactly in polynomial time. We compare our method to state-of-the-art competitors, and we find empirically that controlling the connectivity constraint enables the practitioner to obtain information that is otherwise inaccessible. Finally, we show that our proposed mining tool can be used to better understand how users interact on Twitter, and connectivity aspects of human brain networks with and without Autism Spectrum Disorder (ASD).</EventDescription>
		<EventParent>74611-SESS</EventParent>
		<EventUniqueID>121844</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Classic Graph Structural Features Outperform Factorization-Based Graph Embedding Methods on Community Labeling</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP9</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T11:15:00</EventStartTime>
		<EventEndTime>2022-04-29T11:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>C. Seshadhri</EventSpeakers>
		<EventSpeakerIDs>781516</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121849</EventHandoutURL>
		<EventDescription>Graph representation learning (also called graph embeddings) is a popular technique for incorporating network structure into machine learning models. Unsupervised graph embedding methods aim to capture graph structure by learning a low-dimensional vector representation for each node. Despite the widespread use of these embeddings for a variety of downstream transductive machine learning tasks, there is little principled analysis of the effectiveness of this approach for common tasks. We focus on a popular class of unsupervised embedding techniques that learn low rank factorizations of a vertex proximity matrix (this class includes methods like GraRep, DeepWalk, node2vec, NetMF).  We perform detailed empirical analysis for community labeling over a variety of real and synthetic graphs with ground truth.  In all cases studied, the models trained from embedding features perform poorly on community labeling.  In constrast, a simple logistic model with classic graph structural features handily outperforms the embedding models. For a more principled understanding, we provide a theoretical analysis for the (in)effectiveness of these embeddings in capturing the community structure. We formally prove that popular low-dimensional factorization methods either cannot produce community structure, or can only produce communities that are unstable under small perturbations. </EventDescription>
		<EventParent>74611-SESS</EventParent>
		<EventUniqueID>121849</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Fine-Grained Attributed Graph Clustering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP9</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:35:00</EventStartTime>
		<EventEndTime>2022-04-29T10:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Zhao Kang</EventSpeakers>
		<EventSpeakerIDs>771094</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121853</EventHandoutURL>
		<EventDescription>Graph clustering is a prevalent issue associated with social networks, data mining, and machine learning; its objective is to detect communities or groups in networks. Inspired by the recent success of deep learning (DL), new DL-based graph clustering methods have achieved promising results. However, a deep neural network involves a large number of training parameters. Moreover, existing methods typically select the similarity metric by an ad hoc approach, which considerably affects the resulting output. In this study, we propose a principled graph learning perspective, fine-grained attributed graph clustering. Based on a shallow approach, the proposed method sufficiently exploits both node features and structure information by benefiting from graph convolution. Consequently, a fine-grained graph encoded higher-order relations is automatically learned. Comprehensive experiments on benchmark datasets demonstrate the superiority of the proposed method over state-of-the-art algorithms, including several DL methods.</EventDescription>
		<EventParent>74611-SESS</EventParent>
		<EventUniqueID>121853</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Computation of the Empirical Frechet Mean for Sets of Large Graphs with Applications to Regression</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP9</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:55:00</EventStartTime>
		<EventEndTime>2022-04-29T11:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Daniel Ferguson</EventSpeakers>
		<EventSpeakerIDs>806842</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121886</EventHandoutURL>
		<EventDescription>To characterize the location (mean, median) of a set of graphs, one needs a notion of centrality that is adapted to metric spaces, since graph sets are not Euclidean spaces. A standard approach is to consider the Frechet mean. In this work, we equip a set of graphs with the pseudometric  defined by the $\ell_2$ norm between the eigenvalues of their respective adjacency matrix. Unlike the edit distance, this pseudometric reveals structural changes at multiple scales, and is well adapted to studying various statistical problems for graph-valued data. We describe an algorithm to compute an approximation to the sample Frechet mean of a set of undirected unweighted graphs with a fixed size using this pseudometric.</EventDescription>
		<EventParent>74611-SESS</EventParent>
		<EventUniqueID>121886</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Estimating Mutual Information via Geodesic $k$nn</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP10</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:35:00</EventStartTime>
		<EventEndTime>2022-04-29T10:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Alexander Marx</EventSpeakers>
		<EventSpeakerIDs>799934</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121088</EventHandoutURL>
		<EventDescription>Estimating mutual information (MI) between two continuous random variables $X$ and $Y$ allows to capture non-linear dependencies between them, non-parametrically. As such, MI estimation lies at the core of many data science applications. Yet, robustly estimating MI for high-dimensional $X$ and $Y$ is still an open research question.&#x0D;
&#x0D;
In this paper, we formulate this problem through the lens of manifold learning. That is, we leverage the common assumption that the information of $X$ and $Y$ is captured by a low-dimensional manifold embedded in the observed high-dimensional space and transfer it to MI estimation. As an extension to state-of-the-art $k$NN estimators, we propose to determine the $k$-nearest neighbors via geodesic distances on this manifold rather than from the ambient space, which allows us to estimate MI even in the high-dimensional setting. An empirical evaluation of our method, G-KSG, against the state-of-the-art shows that it yields good estimations of MI in classical benchmark and manifold tasks, even for high dimensional datasets, which none of the existing methods can provide.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74612-SESS</EventParent>
		<EventUniqueID>121088</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Masked Gradient-Based Causal Structure Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP10</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T11:35:00</EventStartTime>
		<EventEndTime>2022-04-29T11:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Zhuangyan Fang</EventSpeakers>
		<EventSpeakerIDs>805820</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121089</EventHandoutURL>
		<EventDescription>This paper studies the problem of learning causal structures from observational data. We reformulate the Structural Equation Model (SEM) with additive noises in a form parameterized by binary graph adjacency matrix and show that, if the original SEM is identifiable, then the binary adjacency matrix can be identified up to super-graphs of the true causal graph under mild conditions. We then utilize the reformulated SEM to develop a causal structure learning method that can be efficiently trained using gradient-based optimization, by leveraging a smooth characterization on acyclicity and the Gumbel-Softmax approach to approximate the binary adjacency matrix. It is found that the obtained entries are typically near zero or one and can be easily thresholded to identify the edges. We conduct experiments on synthetic and real datasets to validate the effectiveness of the proposed method, and show that it readily includes different smooth model functions and achieves a much improved performance on most datasets considered.</EventDescription>
		<EventParent>74612-SESS</EventParent>
		<EventUniqueID>121089</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Learning Infomax and Domain-Independent Representations for Causal Effect Inference with Real-World Data</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP10</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:55:00</EventStartTime>
		<EventEndTime>2022-04-29T11:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Zhixuan Chu</EventSpeakers>
		<EventSpeakerIDs>805902</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121154</EventHandoutURL>
		<EventDescription>The foremost challenge to causal inference with real-world data is to handle the imbalance in the covariates with respect to different treatment options, caused by treatment selection bias. To address this issue, recent literature has explored domain-invariant representation learning based on different domain divergence metrics. In this paper, we reveal the weaknesses of these strategies, i.e., they lead to the loss of predictive information when enforcing the domain invariance; and the treatment effect estimation performance is unstable, which heavily relies on the characteristics of the domain distributions and the choice of domain divergence metrics. Motivated by information theory, we propose to learn the Infomax and Domain-Independent Representations to solve the above puzzles. Our method utilizes mutual information to maximally capture the common predictive information for both treatment and control groups. Moreover, our method filters out the influence of instrumental and irrelevant variables, and thus it effectively increases the predictive ability of potential outcomes.  Experimental results on both the synthetic and real-world datasets show that our method achieves state-of-the-art performance on causal effect inference. Moreover, our method exhibits reliable prediction performances when facing data with different characteristics of data distributions, complicated variable types, and severe covariate imbalance. </EventDescription>
		<EventParent>74612-SESS</EventParent>
		<EventUniqueID>121154</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Cycle-Balanced Representation Learning For Counterfactual Inference</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP10</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T11:15:00</EventStartTime>
		<EventEndTime>2022-04-29T11:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Guanglin Zhou</EventSpeakers>
		<EventSpeakerIDs>806127</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121345</EventHandoutURL>
		<EventDescription>With the widespread accumulation of observational data, researchers obtain a new direction to learn counterfactual effects in many domains (e.g., health care and computational advertising) without Randomized Controlled Trials (RCTs). However, observational data su?er from inherent missing counterfactual outcomes and distribution discrepancy between treatment and control groups due to behaviour preference. Motivated by recent advances in representation learning in domain adaptation, we propose a novel framework based on Cycle-Balanced REpresentation learning for counterfactual inference (CBRE) to solve the above problems. Specifically, we realize a robust and balanced representation for different groups using adversarial training. Meanwhile, we construct an information loop that preserves original data properties cyclically, reducing information loss when transforming data into latent representation space. Experimental results on three real-world datasets demonstrate that CBRE matches/outperforms the state-of-the-art methods, and it has a great potential to be applied to counterfactual inference.</EventDescription>
		<EventParent>74612-SESS</EventParent>
		<EventUniqueID>121345</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Multi-Interest Sequence Modeling for Recommendation with Causal Embedding</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP10</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Penghao Lu</EventSpeakers>
		<EventSpeakerIDs>806831</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121877</EventHandoutURL>
		<EventDescription>Recent methods in sequential recommendation focus on learning multi-interest embedding vectors from a users behavior sequence for the next-item recommendation. However, behavior sequential data may result from users conformity towards popular items, which entangles users real interests and tends to recommend popular items by using interest embeddings. In this paper, we propose a novel multi-interest framework with causal embedding for sequential recommendation, called MiceRec. Specifically, we first obtain two embedding layers from behavior sequence by assigning items with separate embeddings for interest and conformity, then extract multiple pure interests from one embedding layer, while the other for users conformity extraction. According to the colliding effect of causal inference, we mine cause-specific data for training causal embeddings. Our framework significantly outperforms state-of-the-art solutions on two real-world datasets. We further demonstrate that the learned multi-interest embeddings successfully separate from each other, and show that conformity information is almost squeezed out from interest embeddings.&#x0D;
		</EventDescription>
		<EventParent>74612-SESS</EventParent>
		<EventUniqueID>121877</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>FedMe: Federated Learning via Model Exchange</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP11</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:35:00</EventStartTime>
		<EventEndTime>2022-04-29T10:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Koji Matsuda</EventSpeakers>
		<EventSpeakerIDs>806024</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121293</EventHandoutURL>
		<EventDescription>Federated learning is a distributed machine learning method in which a &#x0D;
single server and multiple clients collaboratively build machine learning&#x0D;
models without sharing datasets on clients. &#x0D;
Numerous methods have been proposed to cope with the data heterogeneity issue in federated learning. &#x0D;
Existing solutions require a model architecture tuned by the central server, yet a major technical challenge is that it is difficult to tune the model architecture due to the absence of local data on the central server. &#x0D;
In this paper, we propose {\em Federated learning via Model exchange} &#x0D;
(FedMe), which personalizes models with automatic model architecture tuning &#x0D;
during the learning process. &#x0D;
The novelty of FedMe lies in its learning process: clients exchange their &#x0D;
models for model architecture tuning and model training. &#x0D;
First, to optimize the model architectures for local data, clients tune &#x0D;
their own personalized models by comparing to exchanged models and picking &#x0D;
the one that yields the best performance. &#x0D;
Second, clients train both personalized models and exchanged models by using &#x0D;
deep mutual learning, in spite of different model architectures across &#x0D;
the clients. &#x0D;
We perform experiments on three real datasets and show that FedMe &#x0D;
outperforms state-of-the-art federated learning methods while tuning &#x0D;
model architectures automatically. </EventDescription>
		<EventParent>74613-SESS</EventParent>
		<EventUniqueID>121293</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>StepDIRECT - A Derivative-Free Optimization Method for Stepwise Functions</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP11</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:55:00</EventStartTime>
		<EventEndTime>2022-04-29T11:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Dzung Phan</EventSpeakers>
		<EventSpeakerIDs>750216</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121840</EventHandoutURL>
		<EventDescription>In this paper, we propose the StepDIRECT algorithm for derivative-free optimization (DFO), in which the black-box objective function has a stepwise landscape. Our framework is based on the well-known DIRECT algorithm. By incorporating the local variability to explore the flatness, we provide a new criterion to select the potentially optimal hyper-rectangles. In addition, we introduce a stochastic local search algorithm performingon potentially optimal hyper-rectangles to improve the solution quality and convergence speed. Global convergence of the StepDIRECT algorithm is provided. Numerical experiments on optimization for random forest models and hyper-parameter tuning are presented to support the efficacy of our algorithm. The proposed StepDIRECT algorithm shows competitive performance results compared with other state-of-the-art baseline DFO methods including the original DIRECT algorithm. &#x0D;
		</EventDescription>
		<EventParent>74613-SESS</EventParent>
		<EventUniqueID>121840</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Adaptive Principal Component Analysis</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP11</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T11:15:00</EventStartTime>
		<EventEndTime>2022-04-29T11:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Xiangyu Li</EventSpeakers>
		<EventSpeakerIDs>806777</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121846</EventHandoutURL>
		<EventDescription>Principal Component Analysis (PCA) is a powerful approach that can reduce the dimensionality of input data and increase the ease of data interpretation. One major obstacle for using the traditional PCA is its  dependence on the squared $\ell_2$-norm distance that is highly sensitive to outliers and noisy data. This significantly limits the applicability of the PCA when it is applied to large or high-dimensional datasets. In this paper, we review previous efforts of how to overcome thisproblem and further propose a novel adaptive PCA model. One broadly used hypothesis is that small losses of most data follow the Gaussian distribution and large losses of a few data follow the Laplacian distribution. With this recognition, we choose to use the adaptive loss function that integrates both $\ell_{1}$-norm and squared $\ell_{2}$-norm distances into a single loss function. To solve the resulted non-convex optimization problem, we derive an efficient iterative algorithm that guarantees that both the objective and solution sequences converge to global optimal solutions at a sub-linear convergence rate. The theoretical convergence analysis of our model is not trivial and comprehensively presented in our work. In comparison to other competing dimensionality reduction methods, our experiments on real-world datasets showed a great advantage of our model regardless of whether the data was noisy or not. We anticipate our method will have broad usage for a range of real-world applications.</EventDescription>
		<EventParent>74613-SESS</EventParent>
		<EventUniqueID>121846</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Grp-Fed: Addressing Client Imbalance in Federated Learning via Global-Regularized Personalization</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP11</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Derun Cai</EventSpeakers>
		<EventSpeakerIDs>807098</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121933</EventHandoutURL>
		<EventDescription>Input your abstract, including TeX commands, here.&#x0D;
&#x0D;
The abstract should be no longer than 1500 characters, including spaces.&#x0D;
Only input the abstract text. Don't include title&#x0D;
or author information here.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74613-SESS</EventParent>
		<EventUniqueID>121933</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Leveraging Dependencies among Learned Temporal Subsequences.</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP12</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:35:00</EventStartTime>
		<EventEndTime>2022-04-29T15:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Shoumik Roychoudhury</EventSpeakers>
		<EventSpeakerIDs>789048</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121805</EventHandoutURL>
		<EventDescription>Classifying time-series based on subsequences, known as shapelets, has attracted considerable interest in the community. Most existing shapelet-based time-series classification approaches neglect the temporal dependencies among extracted shapelets. Recently, shapelet-orders that encode the temporal dependencies among pairwise shapelets were shown to be informative features. However, based on a random selection of candidate shapelets, the state-of-the-art model does not guarantee optimal shapelets selection. This, in turn, may lead to inferior quality shapelet-orders. Learning shapelets, insteadof searching, guarantees near-optimal shapelets thus decreasing generalization error. However, the costly initialization approach for learning generalized shapelets significantly limits its scalability in large time-series datasets. We address the problem of leveraging temporal dependencies among generalized shapelets from randomly initialized subsequences by jointly learning from the shapelet-transform space and the shapelet-order space. The underlying hypothesis is that leveraging the temporal dependency information of generalized shapelets improves the classification performance. Furthermore, introducing a randomized subsequence initialization for learning generalized shapelets allows a more scalable shapelet learning approach. The proposed model was significantly more accurate and faster than the baseline alternatives when evaluated on both synthetic and real-world datasets.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74614-SESS</EventParent>
		<EventUniqueID>121805</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Collaborative Attention Mechanism for Multi-Modal Time Series Classification</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP12</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yue Bai</EventSpeakers>
		<EventSpeakerIDs>806753</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121829</EventHandoutURL>
		<EventDescription>Multi-modal time series classification (MTC) uses complementary information from different modalities to improve the learning performance. Obtaining informative modality-specific representation plays an essential role in MTC. Attention mechanism has been widely adopted as an effective strategy for discovering discriminative cues underlying temporal data. However, most existing MTC methods only utilize attention to balance the feature weights within or cross modalities but ignore digging latent patterns from mutual-support information in attention space. Specifically, the attention distributions are different for multiple modalities which are supportive and instructional with each other. To this end, we propose a collaborative attention mechanism (CAM) for MTC based on a novel perspective to utilize attention module. CAM detects the attention differences among multi-modal time series, and adaptively integrates different attention information to benefit each other. We extend the long short-term memory (LSTM) to a Mutual-Aid RNN (MAR) for multi-modal collaboration. CAM takes advantages of modality-specific attention to guide another modality and discover potential information which is hard to be explored by itself. It paves a novel way of employing attention to enhance the capacity of multi-modal representations. Extensive experiments on four multi-modal time series datasets illustrate the CAM effectiveness to improve the single-modal and also boost multi-modal performances.	</EventDescription>
		<EventParent>74614-SESS</EventParent>
		<EventUniqueID>121829</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Contextual Bandits for Advertising Campaigns: A Diffusion-Model Independent Approach</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP12</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:55:00</EventStartTime>
		<EventEndTime>2022-04-29T16:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Alexandra Iacob</EventSpeakers>
		<EventSpeakerIDs>806784</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121850</EventHandoutURL>
		<EventDescription>Motivated by scenarios of information diffusion and advertising in social media, we study an influence maximization problem in which little is assumed to be known about the diffusion network or about the model that determines how information may propagate. In such a highly uncertain environment, one can focus on multi-round diffusion campaigns, with the objective to maximize the number of distinct users that are influenced, starting from a known base of few influential nodes. During a campaign, spread seeds are selected sequentially at consecutive rounds, and feedback is collected consisting of the activated nodes at each round. A rounds impact is then quantified as the number of newly activated nodes. Overall, one must maximize the campaigns total spread, as the sum of rounds rewards. In this setting, an explore-exploit approach could be used to learn the key underlying diffusion parameters, while running the campaign. We describe and compare two methods of contextual multi-armed bandits, with upper-confidence bounds on the remaining potential of influencers, one using a generalized linear model and the Good-Turing estimator for remaining potential (GLM-GT-UCB), and another one that directly adapts the LinUCB algorithm to our setting (LogNorm-LinUCB). We show that they outperform baseline methods using state-of-the-art ideas, on synthetic and real-world data, while at the same time exhibiting different and complementary behavior., depending on the deployment scenarios.</EventDescription>
		<EventParent>74614-SESS</EventParent>
		<EventUniqueID>121850</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Measuring Disentangled Generative Spatio-Temporal Representation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP12</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T16:15:00</EventStartTime>
		<EventEndTime>2022-04-29T16:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Sichen Zhao</EventSpeakers>
		<EventSpeakerIDs>806821</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121871</EventHandoutURL>
		<EventDescription>Disentangled representation learning offers useful properties such as dimension reduction and interpretability, which are essential to modern deep learning approaches. Although deep learning techniques have been widely applied to spatio-temporal data mining, there has been little attention to further disentangle the latent features and understanding their contribution to the model performance, particularly their mutual information and correlation across features. In this study, we adopt two state-of-the-art disentangled representation learning methods and apply them to three large-scale public spatio-temporal datasets. To evaluate their performance, we propose an internal evaluation metric focusing on the degree of correlations among latent variables of the learned representations and the prediction performance of the downstream tasks. Empirical results show that our modified method can learn disentangled representations that achieve the same level of performance as existing state-of-the-art ST deep learning methods in a spatio-temporal sequence forecasting problem. Additionally, we find that our methods can be used to discover real-world spatial-temporal semantics to describe the variables in the learned representation.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74614-SESS</EventParent>
		<EventUniqueID>121871</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Cyclic Transfer Learning for Recommender Systems with Heterogeneous Feedbacks</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP13</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T16:35:00</EventStartTime>
		<EventEndTime>2022-04-29T16:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Xuelian Ni</EventSpeakers>
		<EventSpeakerIDs>805840</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121107</EventHandoutURL>
		<EventDescription>Transfer learning uses auxiliary domains to help complete learning tasks of the target domain. However, the combination of recommendation and transfer learning often has two problems. One is that it's difficult to find an auxiliary domain which is highly related to the target domain. The other is that useful information in auxiliary domains cannot be fully utilized.  To make use of the knowledge in auxiliary domains as much as possible, this paper proposes a cyclic transfer learning method which can transfer the shared knowledge in the auxiliary domain and target domain multiple times. Combining this method with recommendation, this paper presents a recommendation framework based on heterogeneous feedbacks and cyclic transfer learning (HCTLRec). By studying the relationship between different behaviors of users, this paper proposes two specific recommendation algorithms which combine the novel framework with two auxiliary domains. One is to use users' binary attitude information as an auxiliary domain to better represent users' ratings. The other is to use users' trust relationship as an auxiliary domain and make social recommendation. Experiments are carried out on two real-world datasets with trust relationship. The results show that recommendation quality of the two specific algorithms can achieve significant improvement compared with other state-of-the-art algorithms and can effectively relieve the cold-start problem.</EventDescription>
		<EventParent>74615-SESS</EventParent>
		<EventUniqueID>121107</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Private Recommender Systems: How Can Users Build Their Own Fair Recommender Systems Without Log Data?</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP13</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:55:00</EventStartTime>
		<EventEndTime>2022-04-29T16:10:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Ryoma Sato</EventSpeakers>
		<EventSpeakerIDs>801331</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121852</EventHandoutURL>
		<EventDescription>Fairness is a crucial property in recommender systems. Although someonline services have adopted fairness aware systems recently, many other services have not adopted them yet. In this work, we propose methods to enable the users to build their own fair recommender systems. Our methods can generate fair recommendations even when the service does not (or cannot) provide fair recommender systems. The key challenge is that a user does not have access to the log data of other users or the latent representations of items. This restriction prohibits us from adopting existing methods designed for service providers. The main idea is that a user has access to unfair recommendations shown by the service provider. Our methods leverage the outputs of an unfair recommender system to construct a new fair recommender system. We empirically validate that our proposed method improves fairness substantially without harming much performance of the original unfair system.</EventDescription>
		<EventParent>74615-SESS</EventParent>
		<EventUniqueID>121852</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Time-Aware Multi-Interest Capsule Network for Sequential Recommendation</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP13</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T16:15:00</EventStartTime>
		<EventEndTime>2022-04-29T16:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Zhikai Wang</EventSpeakers>
		<EventSpeakerIDs>806808</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121864</EventHandoutURL>
		<EventDescription>In recent years, sequential recommendation has been widely researched, which aims to predict the next item of interest based on users previously interacted item sequence. Many works use RNN to model the user interest evolution over time. However, they typically compute a single vector as the user representation, which is insufficient to capture the variation of user diverse interests. Some non-RNN models employ the dynamic routing mechanism to automatically vote out multiple capsules that represent users diverse interests, but they are ignorant of the temporal information of users historical behaviors, thus yielding suboptimal performance. In this paper, we aim to establish a time-aware dynamic routing algorithm to effectively extract temporal user multiple interests for sequential recommendation. We observe that the significance of an item to user interests may change monotonically over time, and user interests may fluctuate periodically. Thus we propose a novel time-aware multi-interest capsule network named TAMIC that leverages two kinds of time-aware voting gates to control the influence of each interacted item on users current interests during the routing procedure. We further employ an aggregation module to form a temporal multi-interest user representation which is used for next item prediction. Extensive experiments on real-world datasets verify the superior performance of our TAMIC, compared with the SotA methods.</EventDescription>
		<EventParent>74615-SESS</EventParent>
		<EventUniqueID>121864</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>A Non-Sequential Approach to Deep User Interest Model for CTR Prediction</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP13</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Qi Cao</EventSpeakers>
		<EventSpeakerIDs>806827</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121876</EventHandoutURL>
		<EventDescription>Click-Through Rate (CTR) prediction plays an important role in many industrial applications, and recently a lot of deep learning methods attempt to improve the performance through feature interaction or user interest models. However, the existing methods fails to explore the potential interest from user behavior sequence effectively. In this paper, we proposed a Non-sequential Interest Interaction Network (NIIN) to tackle this problem. Specifically, we first design the key-vector storage method to construct the sparse representation for any input behavior sequences. Moreover, our NIIN framework introduces a Time Interest Interaction (TII) module to explore interactions among interests. It first includes an efficient fine-grained attention mechanism to score items in behavior sequence for reserving users diverse interests. After that, our TII module exploits multidimensional partition layer to segment behavior sequence in temporal dimension, and sum pooling operation obtains users interest in different periods. Furthermore, several fully connect layers model interactions among multiple interests to mine potential interest and give the final score of the target item. Experiments on CTR datasets including Alipay, Taobao and Alimama datasets demonstrate that the NIIN framework outperforms the state-of-the-art methods.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74615-SESS</EventParent>
		<EventUniqueID>121876</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Localized Graph Collaborative Filtering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP13</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:35:00</EventStartTime>
		<EventEndTime>2022-04-29T15:50:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yiqi  Wang </EventSpeakers>
		<EventSpeakerIDs>800630</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121928</EventHandoutURL>
		<EventDescription>User-item interactions in recommendations can be naturally denoted as a user-item bipartite graph. Given the success of graph neural networks (GNNs) in graph representation learning, GNN-based Collaborative Filtering (CF) methods have been proposed to advance recommender systems. These methods often make recommendations based on the learned user and item embeddings. However, we found that they do not perform well with sparse user-item graphs which are quite common in real-world recommendations. Therefore, in this work, we introduce a novel perspective to build GNN-based CF methods for recommendations which leads to the proposed framework Localized Graph Collaborative Filtering (LGCF). One key advantage of LGCF is that it does not need to learn embeddings for each user and item, which is challenging in sparse scenarios. Alternatively, LGCF aims at encoding useful CF information into a localized graph and making recommendations based on such graph. Extensive experiments on various datasets validate the effectiveness of LGCF, especially in sparse scenarios. Furthermore, empirical results demonstrate that LGCF provides complementary information to the embedding-based CF model which can be utilized to boost recommendation performance.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74615-SESS</EventParent>
		<EventUniqueID>121928</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Exceptional Model Mining for Repeated Cross-Sectional Data (EMM-RCS)</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP14</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:50:00</EventStartTime>
		<EventEndTime>2022-04-30T09:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Wouter Duivesteijn</EventSpeakers>
		<EventSpeakerIDs>805928</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121175</EventHandoutURL>
		<EventDescription>Repeated Cross-Sectional (RCS) data measures a phenomenon by repeatedly sampling new cases from a population at successive measurement moments. It allows for analyzing societal trends without the need to follow individuals. To gain a deeper understanding of these trends, we propose EMM-RCS, an Exceptional Model Mining instance designed to find subgroups displaying exceptional trend behavior in RCS data. We build quality measures on the standard error, finding various types of exceptionalities within trends (exceptional flattening, slope, deviation from the norm). Additionally, EMM-RCS can handle practical RCS data problems, including uneven spacing of measurements over time, fluctuating sample sizes, and missing data.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74619-SESS</EventParent>
		<EventUniqueID>121175</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Learning from Imbalanced Crowdsourced Labeled Data</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP14</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T09:10:00</EventStartTime>
		<EventEndTime>2022-04-30T09:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Wentao Wang</EventSpeakers>
		<EventSpeakerIDs>793001</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121206</EventHandoutURL>
		<EventDescription>Crowdsourcing has proven to be a cost-effective way to meet the demands for labeled  training data in supervised deep learning models. However, crowdsourced labels are often inconsistent and noisy due to cognitive and expertise differences among crowd workers. Existing approaches either infer latent true labels from noisy crowdsourced labels or learn a discriminative model directly from the crowdsourced labeled data, assuming the latent true label distribution is class-balanced. Unfortunately, in many real-world applications, the true label distribution typically is imbalanced across classes. Therefore, in this paper, we address the problem of learning from crowdsourced labeled data with an imbalanced true label distribution. We propose a new framework, named ``Learning from Imbalanced Crowdsourced Labeled Data" (ICED), which simultaneously infers true labels from imbalanced crowdsourced labeled data and achieves high accuracy on downstream tasks such as classification. The ICED framework consists of two modules, i.e., a true label inference module and a synthetic data generation module, that augment each other iteratively. Extensive experiments conducted on both synthetic and real-world datasets demonstrate the effectiveness of the ICED framework. Our code is available at https://github.com/wentao-repo/ICED.&#x0D;
		</EventDescription>
		<EventParent>74619-SESS</EventParent>
		<EventUniqueID>121206</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Improved Knowledge Distillation via Full Kernel Matrix Transfer</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP14</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T09:50:00</EventStartTime>
		<EventEndTime>2022-04-30T10:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Juhua Hu</EventSpeakers>
		<EventSpeakerIDs>806181</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121418</EventHandoutURL>
		<EventDescription>Knowledge distillation is an effective way for model compression in deep learning. Given a large model (i.e., teacher model), it aims to improve the performance of a compact model (i.e., student model) by transferring the information from the teacher. Various information for distillation has been studied. Recently, a number of works propose to transfer the pairwise similarity between examples to distill relative information. However, most of efforts are devoted to developing different similarity measurements, while only a small matrix consisting of examples within a mini-batch is transferred at each iteration that can be inefficient for optimizing the pairwise similarity over the whole data set. In this work, we aim to transfer the full similarity matrix effectively. The main challenge is from the size of the full matrix that is quadratic to the number of examples. To address the challenge, we decompose the original full matrix with Nystr{\"{o}}m method. By selecting appropriate landmark points, our theoretical analysis indicates that the loss for transfer can be further simplified. Concretely, we find that the difference between the original full kernel matrices between teacher and student can be well bounded by that of the corresponding partial matrices, which only consists of similarities between original examples and landmark points. The empirical study on benchmark data sets demonstrates the effectiveness of the proposed algorithm.</EventDescription>
		<EventParent>74619-SESS</EventParent>
		<EventUniqueID>121418</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Deperturbation of Online Social Networks via Bayesian Label Transition</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP14</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T09:30:00</EventStartTime>
		<EventEndTime>2022-04-30T09:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Jun Zhuang</EventSpeakers>
		<EventSpeakerIDs>806730</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121800</EventHandoutURL>
		<EventDescription>Online social networks (OSNs) classify users into different categories based on their online activities, a task which is referred as a node classification task. Such a task can be solved effectively using Graph Convolutional Networks (GCNs). However, a small number of users, so-called perturbators, may perform random activities on an OSN, which significantly deteriorate the performance of a GCN-based node classification task. Existing works in this direction defend GCNs either by adversarial training or by identifying the attacker nodes followed by their removal. However, both of these approaches require that the attack patterns or attacker nodes be identified first, which is difficult in the scenario when the number of perturbator nodes is very small. In this work, we develop a GCN defense model, namely GraphLT, which uses the concept of label transition. GraphLT assumes that perturbators' random activities deteriorate GCN's performance. To overcome this issue, GraphLT subsequently uses a novel Bayesian label transition model, which takes GCN's predicted labels and applies label transitions by Gibbs-sampling-based inference and thus repairs GCN's prediction to achieve better node classification. Extensive experiments on seven datasets show that GraphLT considerably enhances the performance of the node classifier in an unperturbed environment; furthermore, it validates that GraphLT can successfully repair the node classifier with superior performance than competing methods.</EventDescription>
		<EventParent>74619-SESS</EventParent>
		<EventUniqueID>121800</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Sensitivity-Aware Distance Measurement for Boosting Metric Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP14</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T08:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tan Yu</EventSpeakers>
		<EventSpeakerIDs>806889</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121914</EventHandoutURL>
		<EventDescription>Distance metric learning aims to optimize the distance among samples in the feature space. To enhance the effectiveness of metric learning, a number of methods attempted to weight pairs by hard pair mining. Coarsely, hard pair mining consists of two steps. In the first step, it measures the hardness of each pair. After that, it assigns higher weights to hard pairs when constructing the loss function. Existing deep metric learning methods focus on the second step. They develop many methods to weight each pair based on the measured hardness. In contrast, the first step is rarely exploited. We believe that Without a reliable hardness measurement, even the best weighting method cannot achieve optimal performance. The hardness of a pair in existing metric learning methods is simply measured by the distance between two samples' features in the pair, which we believe is not reliable. In this work, we propose a sensitivity-aware distance measurement (SDM) to enhance the reliability of hardness measurement. SDM augments each sample into a set of samples, and the hardness of a pair is determined by the distance between two samples' augmented sets. The proposed SDM is frustratingly simple and orthogonal to existing mainstream hard pair mining strategies. Systematic experiments are conducted by plugging SDM in several mainstream distance metric learning methods on three public benchmarks. The consistent improvement achieved by SDM demonstrates its effectiveness and versatility.</EventDescription>
		<EventParent>74619-SESS</EventParent>
		<EventUniqueID>121914</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Mining Logical Arithmetic Expressions from Proper Representations</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP15</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T08:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Eitan Kosman</EventSpeakers>
		<EventSpeakerIDs>805486</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121142</EventHandoutURL>
		<EventDescription>Logical-arithmetic expressions are convenient for describing phenomena due to their expressiveness and comprehensibility. Therefore, we propose to target mining logical arithmetic expressions through a novel task called Logical-arithmetic expression mining (LAEM). Its goal is to discover expressive logical expressions that are representative for a database. It accepts a complex database as input and returns a set of representative expressions for the database. Driven by the success of machine learning models to recognize complex patterns, we argue that a thorough modeling of the learned representations could be exploited for generating interesting and representative mathematical expressions. To address this, in this paper we Soft dEcision Tree for logical arithmetic Expressions miNing (SEEN), an algorithm based on representation learning for generating logical expressions. Our mining mechanism partitions the learned representation space and assigns self-labels. Then, we use the self-labels to train a multivariate soft decision tree from which we generate logicalarithmetic expressions. A comprehensive experimental study on 2 diverse real-world datasets shows that the proposed method is able to generate interesting expressions. The implementation is publicly available in https://github.com/ekosman/SEEN.</EventDescription>
		<EventParent>74620-SESS</EventParent>
		<EventUniqueID>121142</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CPTAM: Constituency Parse Tree Aggregation Method</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP15</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:50:00</EventStartTime>
		<EventEndTime>2022-04-30T09:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Adithya Kulkarni</EventSpeakers>
		<EventSpeakerIDs>806381</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121535</EventHandoutURL>
		<EventDescription>Diverse Natural Language Processing tasks employ constituency parsing to understand the syntactic structure of a sentence according to a phrase structure grammar. Many state-of-the-art constituency parsers are proposed, but they may provide different results for the same sentences, especially for corpora outside their training domains. This paper adopts the truth discovery idea to aggregate constituency parse trees from different parsers by estimating their reliability in the absence of ground truth. Our goal is to consistently obtain high-quality aggregated constituency parse trees. We formulate the constituency parse tree aggregation problem in two steps, structure aggregation and constituent label aggregation. Specifically, we propose the first truth discovery solution for tree structures by minimizing the weighted sum of Robinson-Foulds (RF) distances, a classic symmetric distance metric between two trees. Extensive experiments are conducted on benchmark datasets in different languages and domains. The experimental results show that our method, CPTAM, outperforms the state-of-the-art aggregation baselines. We also demonstrate that the weights estimated by CPTAM can adequately evaluate constituency parsers in the absence of ground truth.</EventDescription>
		<EventParent>74620-SESS</EventParent>
		<EventUniqueID>121535</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Knowledge-Enhanced Spherical Representation Learning for Text Classification</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP15</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T09:10:00</EventStartTime>
		<EventEndTime>2022-04-30T09:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Hafsa Ennajari</EventSpeakers>
		<EventSpeakerIDs>806765</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121842</EventHandoutURL>
		<EventDescription>We introduce Knowledge-enhanced Spherical Representation Learning (K-SRL), a generative probabilistic model of text documents that combines word embeddings and knowledge graph embeddings to effectively encode the semantic information of text and the related background knowledge into a low-dimensional representation. More specifically, the proposed model represents each textdocument as a combination of both words and entities linked to an external large knowledge graph and models them as points on the unit hypersphere using the von Mises-Fisher distribution. Furthermore, we develop an efficient variational Bayesian inference algorithm to learn unsupervised text embeddings in the spherical space. Experimental results on multiple benchmark datasets demonstrate that our model outperforms existing probabilistic models on common text classification tasks, including text categorization and sentiment analysis.</EventDescription>
		<EventParent>74620-SESS</EventParent>
		<EventUniqueID>121842</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Adapting Distilled Knowledge for Few-Shot Relation Reasoning over Knowledge Graphs</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP16</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T14:10:00</EventStartTime>
		<EventEndTime>2022-04-30T14:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yiming Zhang</EventSpeakers>
		<EventSpeakerIDs>806799</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121856</EventHandoutURL>
		<EventDescription>Knowledge graphs (KGs) are serving as important resources for many applications, such as semantic search, question answering, or dialogue generation. As one of the fundamental tasks, multi-hop KG reasoning aims at generating effective and explainable relation prediction through reasoning paths. The current methods often require sufficient amount of training data (i.e., fact triples) for each query relation, impairing their applicabilities and performances over few-shot relations (with limited data) which are common in KGs. Despite that some few-shot relation reasoning methods have been proposed, their effectiveness and efficiency remain to be improved. To address these challenges, we propose a novel model called ADK-KG for multi-hop few-shot relation reasoning over KGs. In ADK-KG, we introduce a reinforcement learning framework to model the sequential reasoning process. We further develop a text-enhanced heterogeneous graph neural network to encode node embeddings, where entity and relation embeddings are pre-trained using content information. Later, we employ a task-aware meta-learning algorithm to optimize the model parameters that could be fast adapted for few-shot relations. A knowledge distillation module is further designed to make use of unlabeled data for improving model training. Extensive experiments on three benchmark datasets demonstrate that ADK-KG has satisfactory efficiency and outperforms state-of-the-art approaches.</EventDescription>
		<EventParent>74621-SESS</EventParent>
		<EventUniqueID>121856</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Yacc: A Framework Generalizing Tur\anShadow for Counting Large Cliques</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP16</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T14:50:00</EventStartTime>
		<EventEndTime>2022-04-30T15:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Shweta Jain</EventSpeakers>
		<EventSpeakerIDs>806778</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121866</EventHandoutURL>
		<EventDescription>Counting $k$-cliques is a fundamental problem that has application in many areas eg. dense subgraph discovery, community detection, spam detection, etc. As $k$ increases, the number of $k$-cliques goes up exponentially. Enumeration algorithms (even parallel ones) fail to count $k$-cliques beyond a small $k$. Approximation algorithms, like Tur\anShadow have been shown to perform well upto $k=10$, but are inefficient for larger cliques. The recently proposed Pivoter algorithm significantly improved the state-of-the-art and was able to give exact counts of all $k$-cliques in a large number of graphs.  However, the clique counts of some graphs are still out of reach of these algorithms. &#x0D;
&#x0D;
We revisit the Tur\anShadow algorithm and propose a generalized framework called YACC that leverages several insights about real-world graphs to achieve faster clique-counting. The bottleneck in Tur\anShadow is a recursive subroutine whose stopping condition is based on a classic result from extremal combinatorics called Tur\'an's theorem. Using insights about the structure of real-world graphs and techniques for quickly discovering dense subgraphs, we relax the stopping condition in a systematic way such that we get a smaller recursion tree while still maintaining the guarantees provided by Tur\anShadow. We deploy our algorithm on several real-world data sets and show that YACC reduces the size of the recursion tree and the running time by over an order of magnitude. </EventDescription>
		<EventParent>74621-SESS</EventParent>
		<EventUniqueID>121866</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Heterogeneous Temporal Graph Neural Network</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP16</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:50:00</EventStartTime>
		<EventEndTime>2022-04-30T14:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Yujie Fan</EventSpeakers>
		<EventSpeakerIDs>806816</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121869</EventHandoutURL>
		<EventDescription>Graph neural networks (GNNs) have been broadly studied on dynamic graphs, majority of which focus on graphs with homogeneous structures in the spatial domain. However, many real-world graphs - i.e., heterogeneous temporal graphs (HTGs) - evolve dynamically in the context of heterogeneous graph structures. The dynamics associated with heterogeneity have posed new challenges for HTG representation learning. To solve this problem, in this paper, we propose heterogeneous temporal graph neural network (HTGNN) to integrate both spatial and temporal dependencies while preserving the heterogeneity to learn node representations over HTGs. Specifically, in each layer of HTGNN, we propose a hierarchical aggregation mechanism. To retain the heterogeneity, intra-relation aggregation is first performed on each slice to attentively aggregate information of neighbors with the same type of relation, and then intra-relation aggregation is exploited to gather information over different types of relations; to handle temporal dependencies, across-time aggregation is conducted to exchange information across different graph slices. The proposed HTGNN is a holistic framework tailored heterogeneity with evolution in time and space for HTG representation learning. Extensive experiments are conducted on the HTGs built from different real-world datasets and promising results demonstrate the outstanding performance of HTGNN by comparison with state-of-the-art baselines.</EventDescription>
		<EventParent>74621-SESS</EventParent>
		<EventUniqueID>121869</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>A Strong Node Classification Baseline for Temporal Graphs</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP16</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:30:00</EventStartTime>
		<EventEndTime>2022-04-30T13:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Farimah Poursafaei</EventSpeakers>
		<EventSpeakerIDs>806876</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121912</EventHandoutURL>
		<EventDescription>Many real-world complex systems can be modelled by temporal networks. &#x0D;
Representation learning on these networks often captures their dynamic evolution and is a first step for performing further analysis, e.g. node classification. &#x0D;
Node classification is a fundamental task for graph analysis in general and in the context of temporal graph, is often employed to categories nodes based on their activity patterns. Analysis of existing real world networks from different high-stake domains reveals that the rate of the malicious activities is on uptick, resulting in catastrophic social or economic consequences. This strongly motivates designing accurate node classification methods for temporal graphs. &#x0D;
In this paper, we propose TGBase, for node classification on weighted temporal networks. &#x0D;
TGBase \textit{efficiently} extracts key features to consider the structural characteristics of each node and its neighborhood as well as the intensity and timestamp of the interactions among node pairs.&#x0D;
These features \textit{accurately} differentiate different classes of nodes, as shown on eight real-world benchmark datasets, outperforming multiple state-of-the-art (SOTA) deep/complex models. &#x0D;
Our strong yet simple model is also \textit{generic}, whereas the SOTA contenders are designed often for their specific (class of) datasets. &#x0D;
		</EventDescription>
		<EventParent>74621-SESS</EventParent>
		<EventUniqueID>121912</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Explainable Concept Graph Completion by Bridging Open-Domain Relations and Concepts</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP16</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T14:30:00</EventStartTime>
		<EventEndTime>2022-04-30T14:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Mingming Sun</EventSpeakers>
		<EventSpeakerIDs>794003</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121934</EventHandoutURL>
		<EventDescription>Entity relations and concepts are the most critical information in knowledge-based systems. In traditional closed-domain knowledge bases (KBs), the entity relations and concepts are tightly bound together in the human-designed schema. The relations of entities (relations in the&#x0D;
KB) are correlated with its concepts (entity types in the KB). However, the relations and concepts described by the closed-domain KBs are limited. When we extend the investigation to the open domain, we find that the relations of entities (from Open Information Extraction data&#x0D;
sets) and the concepts of entities (from large-scale concept graphs) re- side in the different data sources, and there is no connection between them. In this paper, we proposed a matching network-based concept graph completion model, which leverages open-domain relations to represent the query entity to predict the entitys concept, where relations are extracted from the open-domain corpus (e.g., Wikipedia). By comparing with other neural baselines, which leverage the whole sentences, we show that our model gets superior performance. Furthermore, we use the open-domain relations as the explanation basis and build an explanation model to answer the question why an entity belongs to a concept. The model gives clear and informative explanations with high relevance to human understanding.&#x0D;
&#x0D;
	&#x0D;
		</EventDescription>
		<EventParent>74621-SESS</EventParent>
		<EventUniqueID>121934</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Invertibility Aware Integration of Static and Time-Series Data: An Application to Lake Temperature Modeling</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP17</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:50:00</EventStartTime>
		<EventEndTime>2022-04-30T14:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Kshitij Tayal</EventSpeakers>
		<EventSpeakerIDs>806046</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121276</EventHandoutURL>
		<EventDescription>Accurate predictions of water temperature are the foundation for many decisions and regulations, with direct impacts on water quality, fishery yields, and power production. Building accurate broad-scale models for lake temperature prediction remains challenging in practice due to the variability in the data distribution across different lake systems monitored by static and time-series data. In this paper, to tackle the above challenges, we propose a novel machine learning based approach for integrating static and time-series data in deep recurrent models, which we call Invertibility-Aware-Long Short-Term Memory(IA-LSTM), and demonstrate its effectiveness in predicting lake temperature. Our proposed method integrates components of the Invertible Network and LSTM  to better predict temperature profiles (forward modeling) and infer the static features (i.e., inverse modeling) that can eventually enhance the prediction when static variables are missing. We evaluate our method on predicting the temperature profile of 450 lakes in the Midwestern U.S. and report relative improvement of 4% to capture data heterogeneity and simultaneously outperform baseline predictions by 12%  when static features are unavailable. &#x0D;
		</EventDescription>
		<EventParent>74622-SESS</EventParent>
		<EventUniqueID>121276</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Fame: Fragment-Based Conditional Molecular Generation for Phenotypic Drug Discovery</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP17</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T14:30:00</EventStartTime>
		<EventEndTime>2022-04-30T14:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Thai-Hoang Pham</EventSpeakers>
		<EventSpeakerIDs>806207</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121439</EventHandoutURL>
		<EventDescription>De novo molecular design is a key challenge in drug discovery due to the complexity of chemical space. Many deep generative models are proposed for generating novel molecules with desired properties. However, most of them focus only on molecular distribution learning and target-based molecular design, thus hindering their potentials in real-world applications. In drug discovery, phenotypic molecular design has advantages over target-based molecular design, especially in first-in-class drug discovery. In this work, we propose the first deep graph generative model (FAME) targeting phenotypic (i.e., gene expression) molecular design. FAME leverages a conditional variational autoencoder framework to learn the conditional distribution generating molecules from gene expression profiles. However, this distribution is difficult to learn due to the complexity of the molecular space and the noisy phenomenon in gene expression data. To tackle these issues, a gene expression denoising (GED) model that employs contrastive objective function is proposed to reduce noise from gene expression data. FAME is then designed to treat molecules as the sequences of fragments and learn to generate these fragments in autoregressive manner. By leveraging the fragment-based generation strategy and the denoised gene expression profiles, FAME can generate novel molecules with desired biological activity.  The experimental results show that FAME outperforms existing methods for phenotypic molecular design.</EventDescription>
		<EventParent>74622-SESS</EventParent>
		<EventUniqueID>121439</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Deepglstm: Deep Graph Convolutional Network and LSTM Based Approach for Predicting Drug-Target Binding Affinity</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP17</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T14:50:00</EventStartTime>
		<EventEndTime>2022-04-30T15:05:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Shrimon Mukherjee</EventSpeakers>
		<EventSpeakerIDs>806364</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121517</EventHandoutURL>
		<EventDescription>Development of new drugs is an expensive and time-consuming process. Due to the world-wide SARS-CoV-2 outbreak, it is essential that new drugs for SARS-CoV-2 are developed as soon as possible. Drug repurposing techniques can reduce the time span needed to develop new drugs by probing the list of existing FDA-approved drugs and their properties to reuse them for combating the new disease. We propose a novel architecture DeepGLSTM, which is a Graph Convolutional network and LSTM based method that predicts binding affinity values  between the FDA-approved drugs and the viral proteins of SARS-CoV-2. Our proposed model has been trained on Davis, KIBA (Kinase Inhibitor Bioactivity), DTC (Drug Target Commons), Metz, ToxCast and STITCH datasets. We use our novel architecture to predict a Combined Score (calculated using Davis and KIBA score) of 2,304 FDA-approved drugs against 5 viral proteins. On the basis of the Combined Score, we prepare a list of the top-18 drugs with the highest binding affinity for 5 viral proteins present in SARS-CoV-2. Subsequently, this list may be used for the creation of new useful drugs.&#x0D;
	&#x0D;
&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74622-SESS</EventParent>
		<EventUniqueID>121517</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Adversarially Reprogramming Pretrained Neural Networks for Data-Limited and Cost-Efficient Malware Detection</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP17</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:30:00</EventStartTime>
		<EventEndTime>2022-04-30T13:45:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Lingwei Chen</EventSpeakers>
		<EventSpeakerIDs>801374</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121851</EventHandoutURL>
		<EventDescription>To mitigate evolving malware attacks, machine learning models have been successfully deployed to detect malware. However, these models are often challenged by data scarcity, design efforts and constrained resources. Inspired by the adversarial vulnerability of machine learning, in this paper, we design a novel model Adv4Mal to adversarially reprogram an ImageNet classification neural network for malware detection in both white-box and black-box settings. As such, a small or moderate amount of data are sufficient to train a promising malware detection model, the varying software features can be uniformly processed without extra efforts, and the majority of computation can be wisely shared and reused to save the resources. This, to the best of our knowledge, has not yet been explored. Specifically, Adv4Mal proceeds by embedding software features into a host image to construct new data, and learning a universal perturbation to be added to all inputs in an imperceptible manner, such that the outputs of the pretrained model can be accordingly mapped to the final detection decisions for all software. We evaluate Adv4Mal on three software datasets. The experimental results demonstrate that Adv4Mal can successfully exploit ImageNet model's learning capability and limited data to achieve high performance in malware detection, and also yield significant advantages of model flexibility to different features, and cost efficiency in computing resources.</EventDescription>
		<EventParent>74622-SESS</EventParent>
		<EventUniqueID>121851</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Unifying Human Mobility Forecasting and Trajectory Semantics Augmentation via Hawkes Process Based LSTM</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP17</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T14:10:00</EventStartTime>
		<EventEndTime>2022-04-30T14:25:00</EventEndTime>
		<EventFilter>SDM22|Contributed</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Pengfei Wang</EventSpeakers>
		<EventSpeakerIDs>806793</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=121854</EventHandoutURL>
		<EventDescription>Human mobility forecasting can help us understand human movements, improve urban planning, and, ultimately, promote the development of livable, sustainable, and viable communities.&#x0D;
While some efforts have been made for forecasting traffic or annotating trajectories, existing methods can be improved via simultaneously conducting human mobility forecasting and trajectory semantics augmentation.&#x0D;
Along this line, in this paper, we provide a joint perspective of point processes and sequential embedding, in order to unify mobility arrival forecasting and trajectory semantics augmentation in a Hawkes-based long short-term memory (LSTM) method.&#x0D;
Specifically, we first regard the traffic trajectories of a region as an arrival sequence according to the arrival time.&#x0D;
Besides, we develop a method that exploits the mutual information of Hawkes processes and LSTM to model the arrival sequences of each region. Particularly, Hawkes processes predict the time and intensities of upcoming mobility arrivals; LSTM learns the embedding of arrivals, and annotates the arrival destinations and trip purposes; the mobility arrival intensities in Hawkes processes are influenced by the hidden states of LSTM.&#x0D;
As applications, we exploit the proposed method to predict 3W (when, where, what) and discover functional regions.&#x0D;
Finally, extensive experimental results with real-world traffic trajectory data demonstrate the enhanced performances of our method.&#x0D;
		</EventDescription>
		<EventParent>74622-SESS</EventParent>
		<EventUniqueID>121854</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Welcome Remarks, IBM and Best Paper Award Announcements, &amp; Presentation: TBD</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T08:00:00</EventStartTime>
		<EventEndTime>2022-04-28T09:45:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Suresh Venkatasubramanian</EventSpeakers>
		<EventSpeakerIDs>807366</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122730</EventHandoutURL>
		<EventParent>74777-SESS</EventParent>
		<EventUniqueID>122730</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-28T08:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Award Announcements and Presentation: The Extreme of Interpretability in Machine Learning: Sparse Generalized Additive Models and Optimal Sparse Decision Trees</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP2</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T08:00:00</EventStartTime>
		<EventEndTime>2022-04-29T09:45:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Cynthia  Rudin</EventSpeakers>
		<EventSpeakerIDs>807367</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122731</EventHandoutURL>
		<EventDescription>With widespread use of machine learning, there have been serious societal consequences from using black box models for high-stakes decisions, including flawed bail and parole decisions in criminal justice, flawed models in healthcare, and black box loan decisions in finance. Transparency and interpretability of machine learning models is critical in high stakes decisions. In this talk, I will focus on two of the most fundamental problems in the field of interpretable machine learning: optimal sparse decision trees and optimal sparse generalized additive models. I will also discuss a hypothesis for why we can find interpretable models with the same accuracy as black box models and discuss recent and future work on dimension reduction for data visualization and model class visualization in variable importance space.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74659-SESS</EventParent>
		<EventUniqueID>122731</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T08:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Next-Generation Intelligent Assistants for AR/VR Devices </EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP3</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T13:30:00</EventStartTime>
		<EventEndTime>2022-04-29T14:45:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Xin Luna  Dong</EventSpeakers>
		<EventSpeakerIDs>807368</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122733</EventHandoutURL>
		<EventDescription>An intelligent assistant shall be an agent that knows you and the world, can receive your requests or predict your needs, and provide you the right services at the right time with your permission. As smart devices such as Amazon Alexa, Google Home, Meta Ray-ban Stories get popular, Intelligent Assistants are gradually playing an important role in people's lives. The Emergence of AR/VR devices brings more opportunities and calls for the next generation of Intelligent Assistants. &#x0D;
&#x0D;
In this talk, we discuss the many challenges and opportunities we face to grow intelligent assistants from server-side to on-device, from voice-only to multi-modal, from context-agnostic to context-aware, and from listening to the users' requests to predicting the user's needs. We expect these new challenges to open doors to new research areas and start a new chapter for providing personal assistance services.&#x0D;
		</EventDescription>
		<EventParent>74660-SESS</EventParent>
		<EventUniqueID>122733</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Closing Ceremony and Presentation: Towards Scalable, Interactive, and Reproducible Data Science</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP4</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T11:00:00</EventStartTime>
		<EventEndTime>2022-04-30T12:30:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Aditya  Parameswaran</EventSpeakers>
		<EventSpeakerIDs>807369</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122734</EventHandoutURL>
		<EventDescription>Data science is typically performed in computational notebooks such as Jupyter with libraries such as pandas and scikit-learn in an ad-hoc, highly iterative manner.  However, this process is not without its challenges, spanning scalability, interactivity, and reproducibility. On the scalability front, popular libraries such as pandas provide flexible means to manipulate, transform, and explore one's data but break down on large datasets, making it difficult to scale up analysis. On the interactivity front, the computational notebook medium requires many lines of code for visual inspection and feedback at each step of exploration, limiting the number of hypotheses explored and insights generated. On the reproducibility front, computational notebooks encourage non-linear execution patterns that are not reproducible, with the data scientist having to keep manually track of program state.&#x0D;
&#x0D;
As part of our research, we have developed open-source tools that target each of the aforementioned challenges, Modin, Lux, and Nbsafety, respectively. Each of these tools have been downloaded hundreds of thousands of times, with millions of downloads overall, and are used by data scientists spanning a variety of sectors. I will introduce these three tools, the underlying motivation and research challenges, and describe some lessons learned along the way in having impact with open-source software.&#x0D;
&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74662-SESS</EventParent>
		<EventUniqueID>122734</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T11:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>See Tutorial Webpage for Tutorial Information</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT1</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T17:15:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tutorial Attendees</EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122719</EventHandoutURL>
		<EventDescription>Abstract&#x0D;
&#x0D;
		</EventDescription>
		<EventParent>74649-SESS</EventParent>
		<EventUniqueID>122719</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>See Tutorial Webpage for Tutorial Information</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT2</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T10:30:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tutorial Attendees</EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122720</EventHandoutURL>
		<EventDescription>Abstract</EventDescription>
		<EventParent>74650-SESS</EventParent>
		<EventUniqueID>122720</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Tutorial Webpage for Tutorial Information</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT3</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T10:30:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tutorial Attendees</EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122722</EventHandoutURL>
		<EventDescription>Abstract&#x0D;
		</EventDescription>
		<EventParent>74652-SESS</EventParent>
		<EventUniqueID>122722</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>See Tutorial Webpage for Tutorial Information</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT4</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:30:00</EventStartTime>
		<EventEndTime>2022-04-30T15:30:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Tutorial Attendees</EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=122721</EventHandoutURL>
		<EventDescription>Abstract&#x0D;
		</EventDescription>
		<EventParent>74651-SESS</EventParent>
		<EventUniqueID>122721</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<DirectLinkEnabled>0</DirectLinkEnabled>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>WS1 See Workshop Webpage for Workshop Information Abstract</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>WS1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Workshop Attendees</EventSpeakers>
		<EventSpeakerIDs>800620</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=123362</EventHandoutURL>
		<EventDescription>Workshop 1 - See &lt;a href="https://sites.google.com/view/tdaworkshopatsdm22/home"&gt; https://sites.google.com/view/tdaworkshopatsdm22/home&lt;/a&gt; for Schedule&#x0D;
		</EventDescription>
		<EventParent>74637-SESS</EventParent>
		<EventUniqueID>123362</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Workshop 2 is CANCELLED</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>WS2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Workshop Attendees</EventSpeakers>
		<EventSpeakerIDs>800620</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=123361</EventHandoutURL>
		<EventDescription>THIS WORKSHOP IS CANCELLED 04/04/2022.</EventDescription>
		<EventParent>74641-SESS</EventParent>
		<EventUniqueID>123361</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>WS3 See Workshop Webpage for Workshop Information Abstract</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>WS3</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T12:15:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs></EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers>Workshop Attendees</EventSpeakers>
		<EventSpeakerIDs>800620</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>Abstract</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_talk.cfm?p=123363</EventHandoutURL>
		<EventDescription>&lt;a href="https://bird-initiative.com/ribmls2022/"&gt;&#x0D;
https://bird-initiative.com/ribmls2022/&lt;/a&gt;&#x0D;
&#x0D;
Workshops/minisymposia follow their own posted schedule. Participants are strongly encouraged to consult the website linked above.</EventDescription>
		<EventParent>74654-SESS</EventParent>
		<EventUniqueID>123363</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T12:15:00</EventStartTime>
		<EventEndTime>2022-04-28T13:30:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74605-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-28T12:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T15:30:00</EventStartTime>
		<EventEndTime>2022-04-28T16:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74606-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-28T15:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T09:45:00</EventStartTime>
		<EventEndTime>2022-04-29T10:15:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74616-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-29T09:45:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T12:15:00</EventStartTime>
		<EventEndTime>2022-04-29T13:30:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74617-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-29T12:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T14:45:00</EventStartTime>
		<EventEndTime>2022-04-29T15:15:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74618-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-29T14:45:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T17:15:00</EventStartTime>
		<EventEndTime>2022-04-29T18:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74961-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-29T17:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T10:30:00</EventStartTime>
		<EventEndTime>2022-04-30T11:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74646-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-30T10:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T12:30:00</EventStartTime>
		<EventEndTime>2022-04-30T13:30:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74647-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-30T12:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Coffee Break</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T09:45:00</EventStartTime>
		<EventEndTime>2022-04-28T10:15:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74604-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-28T09:45:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP1 Foundations I</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T12:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807997</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806812,806850,806902,806916,806752</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74599</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74599-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP10 Causal Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP10</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T12:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806724</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>799934,805820,806831,806127,805902</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74612</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74612-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP11 Optimization</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP11</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T12:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>808001</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>750216,806024,806777,807098</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74613</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74613-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP12 Time Series II</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP12</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T17:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806703</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806753,789048,806784,806821</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74614</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74614-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP13 Recommender Systems</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP13</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T17:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>805918</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>805840,806808,801331,806827,800630</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74615</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74615-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP14 Foundations II</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP14</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>793057</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>793001,805928,806181,806889,806730</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74619</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74619-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP15 Text/NLP</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP15</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T10:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806810</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806765,805486,806381</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74620</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74620-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP16 Graph Mining &amp; Analysis IV</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP16</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:30:00</EventStartTime>
		<EventEndTime>2022-04-30T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806809</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806778,806816,794003,806799,806876</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74621</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74621-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP17 Applications III</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP17</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:30:00</EventStartTime>
		<EventEndTime>2022-04-30T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807403</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806207,806046,806364,801374,806793</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74622</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74622-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP2 Graph Mining &amp; Analysis I</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T12:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807998</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806711,806712,806741,805782,806790</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74600</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74600-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP3 Applications I</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP3</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T12:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>805916</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800639,805865,800638,807098,805487</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74596</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74596-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP4 Graph Mining &amp; Analysis II</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP4</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>778994</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>805935,806703,801426,789375,806713</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74601</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74601-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP5 Time Series I</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP5</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>794663</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806042,806728,793446,794663,806866</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74602</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74602-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP6 Clustering and Anomaly Detection</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP6</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T15:30:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806870</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>805481,805891,805915,806853,806382</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74603</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74603-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP7 Deep Learning I</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP7</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:00:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806889</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806764,806723,780836,806893,806718,794533</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74607</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74607-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP8 Applications II</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP8</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:00:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807402</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>805781,806075,806883,806779,801501</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74608</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74608-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>CP9 Graph Mining &amp; Analysis III</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CP9</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T12:15:00</EventEndTime>
		<EventFilter>SDM22|Contributed|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>806870</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>806755,806842,800629,781516,771094</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74611</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74611-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-29T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Doctoral Forum Best Student Poster Award Announcement</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:00:00</EventStartTime>
		<EventEndTime>2022-04-30T08:30:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74661-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-30T08:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>Doctoral Forum Poster Session</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>CB</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T18:00:00</EventStartTime>
		<EventEndTime>2022-04-29T20:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName></EventHandoutName>
		<EventHandoutURL></EventHandoutURL>
		<EventDescription>A list of Doctoral Forum posters is available at &#x0D;
&lt;a &#x0D; href="https://www.siam.org/conferences/cm/program/special-&#x0D;
events/sdm22-special-&#x0D;
events"&gt;https://www.siam.org/conferences/cm/program/specia&#x0D;
l-&#x0D;
events/sdm22-special-events&lt;/a&gt;. &#x0D;
&#x0D;
&#x0D;
&#x0D;
		</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74644-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>0</AutoRecord>
		<EnabledForIAV>0</EnabledForIAV>
		<start>2022-04-29T18:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>IP1 Welcome Remarks, IBM and Best Paper Award Announcements, &amp; Presentation: TBD</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T08:00:00</EventStartTime>
		<EventEndTime>2022-04-28T09:45:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>761897</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>807366</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74777</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74777-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<DirectLinkEnabled>1</DirectLinkEnabled>
		<DirectLinkRecordingEnabled>1</DirectLinkRecordingEnabled>
		<start>2022-04-28T08:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>IP2 Award Announcements and Presentation: The Extreme of Interpretability in Machine Learning: Sparse Generalized Additive Models and Optimal Sparse Decision Trees</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP2</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T08:00:00</EventStartTime>
		<EventEndTime>2022-04-29T09:45:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>761897</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>807367</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74659</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74659-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<DirectLinkEnabled>1</DirectLinkEnabled>
		<DirectLinkRecordingEnabled>1</DirectLinkRecordingEnabled>
		<start>2022-04-29T08:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>IP3 Next-Generation Intelligent Assistants for AR/VR Devices </EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP3</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T13:30:00</EventStartTime>
		<EventEndTime>2022-04-29T14:45:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>801970</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>807368</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74660</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74660-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<DirectLinkEnabled>1</DirectLinkEnabled>
		<DirectLinkRecordingEnabled>1</DirectLinkRecordingEnabled>
		<start>2022-04-29T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>IP4 Closing Ceremony and Presentation: Towards Scalable, Interactive, and Reproducible Data Science</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>IP4</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T11:00:00</EventStartTime>
		<EventEndTime>2022-04-30T12:30:00</EventEndTime>
		<EventFilter>SDM22|Invited Speaker|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>801970</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>807369</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74662</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74662-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<DirectLinkEnabled>1</DirectLinkEnabled>
		<DirectLinkRecordingEnabled>1</DirectLinkRecordingEnabled>
		<start>2022-04-30T11:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>MT1 Tutorial: Socially Responsible AI for Data Mining: Theories and Practice </EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT1</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T17:15:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>783882,789143,807358,729848</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74649</EventHandoutURL>
		<EventDescription>&lt;a href="https://sites.google.com/asu.edu/srai4dm/"&gt;&#x0D;
https://sites.google.com/asu.edu/srai4dm&#x0D;
&lt;/a&gt;&#x0D;
&#x0D;
		</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74649-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>MT2 Tutorial: Matrix Factorizations with Binary Constraints</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT2</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T10:30:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807354,807353</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74650</EventHandoutURL>
		<EventDescription>&lt;a href="https://sibylse.github.io/TutorialMF/"&gt;&#x0D;
https://sibylse.github.io/TutorialMF/&lt;/a&gt;</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74650-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>MT3 Tutorial: Network Embedding for Role Discovery: Concepts, Tools, and Applications</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT3</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T08:30:00</EventStartTime>
		<EventEndTime>2022-04-30T10:30:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807360,783892,772831</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74652</EventHandoutURL>
		<EventDescription>&lt;a href="https://markheimann.github.io/tutorials/NetworkRoleDiscovery"&gt;&#x0D;
https://markheimann.github.io/tutorials/NetworkRoleDiscovery&lt;/a&gt;</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74652-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T08:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>MT4 Tutorial: Noise Enhancement: Techniques and Applications</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>MT4</EventNumber>
		<EventDate>Apr 30, 2022</EventDate>
		<EventStartTime>2022-04-30T13:30:00</EventStartTime>
		<EventEndTime>2022-04-30T15:30:00</EventEndTime>
		<EventFilter>SDM22|Minitutorial|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>801959,807355</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800621</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74651</EventHandoutURL>
		<EventDescription>&lt;a href="https://reyhanehabdolazimi.com/tutorials/SDM2022"&gt;&#x0D;
https://reyhanehabdolazimi.com/tutorials/SDM2022&lt;/a&gt;</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74651-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<AutoRecord>1</AutoRecord>
		<EnabledForIAV>1</EnabledForIAV>
		<MeetingIAVMode>Meeting</MeetingIAVMode>
		<PublishAutoRecordedVideo>1</PublishAutoRecordedVideo>
		<Capacity>300</Capacity>
		<start>2022-04-30T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>PD1 Data Science in and across the Disciplines: Forming the Next Generation of Scholars</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>PD1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T16:00:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|Panel Discussion|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>733575</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>807931,807932,807933,807944</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74653</EventHandoutURL>
		<EventDescription></EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74653-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-28T16:00:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>PD2 ****CANCELLED**** Doctoral Forum Panel</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>PD2</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T15:15:00</EventStartTime>
		<EventEndTime>2022-04-29T17:15:00</EventEndTime>
		<EventFilter>SDM22|Panel Discussion|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>796990</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74663</EventHandoutURL>
		<EventDescription>This session has been CANCELLED.&#x0D;
&#x0D;
A mentorship panel for PhD students with senior leaders in &#x0D;
the field, which will provide perspectives and tips for &#x0D;
graduate studies and what comes after graduation.&#x0D;
&#x0D;
		</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74663-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-29T15:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>WS1 Workshop 1, Full Day Workshop: Applications of Topological Data Analysis (TDA) to Data Science, Artificial Intelligence, and Machine Learning</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>WS1</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T10:15:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>800616,807340,782360,715479</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800620</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74637</EventHandoutURL>
		<EventDescription>&lt;a href="https://sites.google.com/view/tdaworkshopatsdm22/home"&gt;&#x0D;
https://sites.google.com/view/tdaworkshopatsdm22/home&lt;/a&gt;&#x0D;
&#x0D;
Workshops follow their own posted schedule. Workshop participants are strongly encouraged to consult each workshop website linked above.</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74637-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-28T10:15:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>WS2 ****CANCELLED**** XPERT4CQA: Expert Recommendation for Community Question Answering</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>WS2</EventNumber>
		<EventDate>Apr 28, 2022</EventDate>
		<EventStartTime>2022-04-28T13:30:00</EventStartTime>
		<EventEndTime>2022-04-28T18:00:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807342,807341</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800620</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74641</EventHandoutURL>
		<EventDescription>THIS WORKSHOP IS CANCELLED 04/04/2022.&#x0D;
		</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74641-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-28T13:30:00</start>
	</meeting>
	<meeting>
		<Confcode>SDM22</Confcode>
		<EventName>WS3 Half Day Minisymposium: Research Issues on Bridging Machine Learning and Simulation Minisymposium</EventName>
		<EventSubName></EventSubName>
		<Poster></Poster>
		<EventNumber>WS3</EventNumber>
		<EventDate>Apr 29, 2022</EventDate>
		<EventStartTime>2022-04-29T10:15:00</EventStartTime>
		<EventEndTime>2022-04-29T12:15:00</EventEndTime>
		<EventFilter>SDM22|</EventFilter>
		<EventLocation></EventLocation>
		<EventRoom></EventRoom>
		<FloorPlan></FloorPlan>
		<EVENT_FEE></EVENT_FEE>
		<EventKeywords></EventKeywords>
		<EventChairs>807365</EventChairs>
		<EventModerators></EventModerators>
		<EventSpeakers></EventSpeakers>
		<EventSpeakerIDs>800620</EventSpeakerIDs>
		<EventSponsor></EventSponsor>
		<EventHandoutName>session</EventHandoutName>
		<EventHandoutURL>http://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74654</EventHandoutURL>
		<EventDescription>&lt;a href="https://bird-initiative.com/ribmls2022/"&gt;&#x0D;
https://bird-initiative.com/ribmls2022/&lt;/a&gt;&#x0D;
&#x0D;
Workshops/minisymposia follow their own posted schedule. Participants are strongly encouraged to consult the website linked above.</EventDescription>
		<EventParent></EventParent>
		<EventUniqueID>74654-SESS</EventUniqueID>
		<STATUS>active</STATUS>
		<start>2022-04-29T10:15:00</start>
	</meeting>
</meetings>
